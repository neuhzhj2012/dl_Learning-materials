###### 相关文章

> [零基础入门深度学习](https://www.zybuluo.com/hanbingtao/note/433855)

## 数学相关

- 函数的解析解和数值解

> **解析解**。当模型和损失函数形式较为简单时，误差最小化问题的解可以直接用公式表达出来。
> 
> **数值解**。大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。

## 数据处理

- 数据增强/数据扩充/数据增广
1. 翻转和裁剪。包括水平和上下翻转、随机和固定比例的位置裁剪
2. 颜色变化。包括亮度、饱和度、色调、对比度
3. 上述两种方法的融合
4. 分类与检测的数据增强代码[imgaug](https://github.com/aleju/imgaug)

## 模型训练

- 分布式训练
1. 出发点：提高模型训练速度
2. 分类：[数据并行和模型并行](https://leimao.github.io/blog/Data-Parallelism-vs-Model-Paralelism/),现在显卡资源充足，多使用数据并行训练网络
3. [数据并行](https://zh.d2l.ai/chapter_computational-performance/multiple-gpus.html)

> batch数据等分为k份并分给每块显卡一部分；
> k块显卡均独立维护一份完整的模型参数;
> 每块显卡根据小batch分别计算模型参数的本地梯度；
> k块显卡的显存上的本地梯度相加，便得到当前的小批量随机梯度。之后，每块GPU都使用这个小批量随机梯度分别更新相应显存所维护的那一份完整的模型参数。

4. 模型并行， 如Alexnet模型最初的训练方式

> 模型的网络层等分为k份并分配到每块显卡一部分；
> 浅层网络所在的显卡接受batch数据，深层网络所在的显卡等待浅层网络的显卡输出后作为自身的输入；
> bp时先计算深层网络所在显卡的梯度，然后回传至浅层网络所在的显卡

- 模型微调(fine-tune)
1. 出发点

> 样本集构建成本高，如100类椅子的识别需要对每类椅子拍摄1000张不同角度图片
> 基于数量少的样本训练后模型达不到实用要求;
> 复杂模型效果好，但直接应用于数量少的样本时易过拟合;

2. 模型微调的前提条件

> 假设源数据集上学习到的知识适用于目标数据集;
> 假设源模型的输出层跟源数据集的标签紧密相关，故目标模型不予使用

3. 优势：目标数据集小于源数据集大小时，有助于提高模型的泛化能力
4. 训练步骤

> 源数据集上训练一个神经网络得到基础模型;
> 假设目标模型与源模型除输出层外的结构和参数均相同；
> 设定目标模型的输出类别，并初始化参数；
> from strach开始训练输出层。 然后再微调其他层参数

## 子领域

- 分类任务
1. 目标是识别图片中的主体类别
2. 前提条件是假设每张图像中只有一个目标主体
3. 评价指标是准确率和召回率
- 检测任务
1. 目标是得到图片中感兴趣目标的类别和位置信息。直观理解该任务的处理过程是在输入图像中采样大量的区域，然后判断这些区域中是否包含我们感兴趣的目标，并调整区域边缘从而更准确地预测目标的真实边界框
2. 图片的坐标原点在图像的左上角，原点往右和往下分别为 x 轴和 y 轴的正方向。
3. 位置信息的表示：左上和右下点对、左上和宽高、中心点和宽高信息。
4. 评价指标是[map](https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173),其中ap是就单个类别平均准确率。预测正确包含两部分：网络预测pred_box中的物体类别为该类别，pred_box与gt_box之间交并比大于某阈值。平均准确率是指基于该类所有样本预测结果生成的precision-recall曲线，经修正后(左侧准确率不小于右侧准确率)对所有样本准确率求的平均值
5. 基于锚框的训练。每个锚框是一个训练样本。其中正样本为与gt-box有最大交并比的anchor；与gt-box交并比大于0.7的anchor。负样本为与gt-box交并比小于0.3的anchor。如果一个锚框没有被分配真实边界框，我们只需将该锚框的类别设为背景。计算过程可参考[这里](https://zh.d2l.ai/chapter_computer-vision/anchor.html#%E6%A0%87%E6%B3%A8%E8%AE%AD%E7%BB%83%E9%9B%86%E7%9A%84%E9%94%9A%E6%A1%86)

> 正样本的两种情况：与gt-box有最大交并比的anchor和与gt-box交并比大于0.7的anchor。前者是保证小目标可以有对应anchor，后者保证获得足够多的正样本。
> 计算过程：
> 锚框与gt-box组成矩阵，如锚框为纵坐标，gt-box为横坐标。
> 每次找到矩阵中的最大值，删除当前位置的行列，该位置为当前锚框对应的真实的边界框；
> 在剩余矩阵中继续找最大值，得到当前锚框对应的真实边界框；
> 重复上述过程至所有真实边界框都分配一个锚框；
> 剩余锚框与gt-box计算交并比，如果大于阈值则为当前锚框分配真实边界框；

6. [检测算法评估标准](https://github.com/rafaelpadilla/Object-Detection-Metrics)，直观理解详见[这里](https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173)
- NAS
1. 搜索空间

2. 搜索算法

> 基于RL的搜索算法
> 
> 基于梯度的搜索算法
> 
> 基于进化搜索算法
> 
> 搜索算法比较：
> 
> 进化搜索能够很好地满足限制因素（如FLOPs或速度）。为了优化FLOPs或速度，基于RL的方法需要对反馈函数仔细调参。而基于梯度的方法则需要对损失函数仔细调参。
