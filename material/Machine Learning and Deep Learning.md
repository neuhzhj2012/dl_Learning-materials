## 基础知识

### 数学相关概念

###### 全概率公式

设事件B1、B2、B3…Bn 构成一个完备事件组，即它们两两互不相容，其和为全集；并且P(Bi)大于0，则对任一事件A发生的概率有如下表示。

$$
P(A)=\sum_{i=1}^{n}P(B_{i})P(A|B_{i})
$$

###### 贝叶斯公式

随机事件A发生的情况下，是由原因Bi引起的概率表示如下。

$$
P(B_{i}|A)=\frac{P(B_{i})P(A|B_{i})}{P(A)}=\frac{P(B_{i})P(A|B_{i})}{\sum_{i=1}^{n}P(B_{i})P(A|B_{i})}
$$

###### 先验概率

根据以往经验和分析得到的概率，**用于执因求果**。如全概率公式中P(Bi)为先验概率，用于求事件A发生的概率。

###### 后验概率

某件事已经发生，想要计算这件事发生的原因是由某个因素引起的概率，**用于知果求因**。如贝叶斯公式中P(Bi|A)为后验概率，用于表示A发生是由Bi事件引起的概率。

###### [ 似然函数](https://zh.wikipedia.org/wiki/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0)

是一种关于[统计模型](https://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B "统计模型")中参数的函数，表示模型参数中的似然性。**似然性**则是用于在已知某些观测所得到的结果时，对有关事物之性质的参数进行估值。可理解为已知事件A发生的条件下，该事物性质的参数是b的可能性。

$$
L(b|A) = \alpha P(A|B=b)
$$

似然函数的重要性不是它的具体取值，而是当参数变化时函数到底变小还是变大

对同一个似然函数，其所代表的模型中，某项参数值具有多种可能，但如果存在一个参数值，使得它的函数值达到最大的话，那么这个值就是该项参数最为“合理”的参数值。 **极大(最大)似然估计**，表示**知果求最可能的原因**

对数函数是严格单增的，所以极大*对数似然*的解与极大似然的解是相同的

###### [先验概率、后验概率、似然函数及贝叶斯公式的理解](https://www.zhihu.com/question/24261751/answer/158547500)

$$
P(B_{i}|A)=\frac{P(B_{i})P(A|B_{i})}{P(A)}=\frac{P(B_{i})P(A|B_{i})}{\sum_{i=1}^{n}P(B_{i})P(A|B_{i})}
$$

贝叶斯公式中P(Bi|A)表示后验概率，P(Bi)表示先验概率，P(A|Bi)表示似然函数中参数是Bi时A的概率，P(A)表示一种事实的概率。

###### [拉格朗日函数](https://zh.wikipedia.org/wiki/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0)

在数学的最优化问题中，拉格朗日乘数法是一种寻找多元函数在其变量受到一个或多个条件约束时的极值的方法。

###### 线性方程

指未知数都是一次的方程，包含两个未知数的一次方程为二元一次方程。其本质是等式两边乘以任何相同的非零数，方程式的解不变。

###### NP(Nondeterministic Polynomially)问题

非确定性多项式问题是指一个复杂问题不能确定是否在多项式时间内找到答案，但是可以在多项式时间内验证答案是否正确。NP类问题很多，如完全子图问题、[图着色问题](https://baike.baidu.com/item/%E5%9B%BE%E7%9D%80%E8%89%B2%E9%97%AE%E9%A2%98)、旅行商([TSP](https://baike.baidu.com/item/TSP/2905216))问题等。

###### 对偶形式

pass

### 数据结构相关概念

##### [树](https://zh.wikipedia.org/wiki/%E6%A0%91_%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84)

![树的深度与高度图解](D:\Project\MyGithub\dl_Learning-materials\material\img\树的高度与深度.jpg)

                                                            图片来着[这里 ](https://stackoverflow.com/questions/2603692/what-is-the-difference-between-tree-depth-and-height)          

- **深度**：对于任意节点n,n的深度为从根到n的唯一路径长，**根的深度为0**；
- **高度**：对于任意节点n,n的高度为从n到一片树叶的最长路径长，**所有树叶的高度为0**；
- **节点的度**：一个节点含有的子树的个数称为该节点的度；
- **树的度**：一棵树中，最大的节点度称为树的度；
- **叶节点**或**终端节点**：度为零的节点；
- **非终端节点**或**分支节点**：度不为零的节点；
- **父亲节点**或**父节点**：若一个节点含有子节点，则这个节点称为其子节点的父节点；
- **孩子节点**或**子节点**：一个节点含有的子树的根节点称为该节点的子节点；
- **兄弟节点**：具有相同父节点的节点互称为兄弟节点；
- 节点的**层次**：从根开始定义起，根为第1层，根的子节点为第2层，以此类推；
- **堂兄弟节点**：父节点在同一层的节点互为堂兄弟；
- **节点的祖先**：从根到该节点所经分支上的所有节点；
- **子孙**：以某节点为根的子树中任一节点都称为该节点的子孙。
- **森林**：由m（m>=0）棵互不相交的树的集合称为森林；

### 机器学习相关概念

###### 数据集

> 训练集用于训练模型；
> 
> 验证集用于模型的选择；
> 
> 测试集用于最终对学习方法的评估；

###### 统计学习方法概论

统计学习方法是基于数据构建概率统计模型并运用模型对数据进行预测与分析的学科，由**监督学习**（supervised learning），**非监督学习**，**半监督学习和强化学习**（reinforcement learning）等组成。统计学习方法的三要素如下。

> 模型：所要学习的条件概率分布或决策函数；
> 
> 策略：学习或选择最优模型的准则，即损失函数(度量模型一次预测的好坏)和风险函数(度量平均意义下模型预测的好坏)的构建；(定义损失函数，并将其极小化)
> 
> 算法：学习模型的具体计算方法，即求解最优化问题的算法

###### 生成模型与判别模型

- 定义

> 生成模型：由数据学习联合概率分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型。即模型表示了给定输入X产生输出Y的生成关系；
> 
> 判别模型：由数据直接学习决策函数f(X)或条件概率分布P(Y|X)作为预测模型。即模型表示给定输入X时预测什么样的输出Y；

- 常见模型：

> 生成模型包括朴素贝叶斯法和隐马尔科夫模型；
> 
> 判别模型包括：感知机、k近邻法、决策树、逻辑斯谛回归模型、最大熵模型、支持向量机、提升方法和条件随机场等；

- 优缺点

> 生成方法可还原出联合概率分布P(X,Y);学习收敛速度较判别方法更快；存在隐变量时仍可用生成方法，此时判别方法不可用；
> 
> 判别方法学习的准确率更高；可对数据进行抽象、定义特征并使用特征，简化学习问题。

##### 模型选择

旨在避免过拟合并提高模型的预测能力。**模型选择常用的方法：正则化和交叉验证**。模型对未知数据的预测能力称为**泛化能力**。

> 过拟合 指学习时选择的模型包含的参数过多，以致于出现这一模型对已知数据预测的很好，但对未知数据预测很差的现象

###### 正则化

正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或罚项。正则化项一般是模型复杂度的单调递增函数，如正则化项可以是模型参数向量的范数。

###### 交叉验证

数据充足时，选择对验证集有最小预测误差的模型。否则采用交叉验证的方法，其基本思想是重复的使用数据，把数据分为训练集与测试集，在此基础上反复训练、测试以及模型选择。包括简单交叉验证，S折交叉验证和留一交叉验证。

> 简单交叉验证 将数据切分为训练集(70%)和测试集(30%)，然后用训练集在不同条件下(eg:不同参数个数)训练模型；然后在测试集上评测各模型的测试误差，选择误差最小的模型；
> 
> S折交叉验证 随机将数据切分为S个互不相交大小相同的子集，然后利用S-1个子集作为训练集，剩余的一个作为测试集训练模型。将上述过程对可能的S中集合重复进行，最后选择S次评测中测试误差最小的模型。该方法应用最多；
> 
> 留一交叉验证 S折交叉验证的特殊情况，即S等于样本容量。

###### 泛化能力

通常基于测试误差评价模型的泛化能力，但由于测试集的有限性，导致评测结果是不可靠的。因此使用泛化误差来反应模型的泛化能力。

### 评价指标

##### 分类问题

pass

### 距离度量函数

##### Lp距离

向量xi与xj的Lp距离定义如下，其中p>=1。当p=2时称为**欧式距离**(Euclidean distance)，当p=1时为**曼哈顿距离**(Manhattan distance)

$$
L_{p}(x_{i}, x_{j})=\left ( \sum_{l=1}^{n}\left | x_{i}^{(l)} - x_{j}^{(l)} \right |^{p} \right )^{\frac{1}{p}}
$$

##### 函数汇总

- 符号函数

$$
sign(x)=\left\{\begin{matrix}
+1,  x\geq 0 & \\ 
-1,  x< 0& 
\end{matrix}\right.
$$

- 指示函数，表示其中有哪些元素属于某一子集*A*。

$$
I_{A}(x)=\left\{\begin{matrix}
1 & \\ 
0 & 
\end{matrix}\right.  \begin{matrix}
x \in A& \\ 
x \not\in A& 
\end{matrix}
$$

- argmax, 表示求函数最大值的参数的函数
  
  > y = max f(t) 代表：y 是f(t)函式所有的值中最大的output。
  > 
  > y = argmax f(t) 代表：y 是f(t)函式中，会产生最大output的那个参数t。

## 机器学习方法

##### 感知机

###### 原始形式

- 二分类的线性分类模型，输入为实例的特征向量，输出为实例的类别。**感知机模型为激活函数是符号函数的神经元**，是神经网络与支持向量机的基础。

$$
f(x)=sign(w\cdot x +b)
$$

- 学习策略为经验风险函数极小化，用于表示所有误分类点(集合M)到分类超平面的距离和(不考虑超平面的模值1/|w|)。

$$
L(w,b)=-\sum_{x_{i}\varepsilon M}y_{i}(w\cdot x_{i}+b)
$$

算法是误分类数据驱动的，采用随机梯度下降法(stochastic gradient descent)。首先，任选一个超平面w0,b0，然后用梯度下降法不断极小化目标函数。极小化过程中每次随机选取一个误分类点使其梯度下降。

> 直观理解是当一个实例点被误分类时，调整w,b的值，使分离超平面向该误分类点的一侧移动，以减少误分类点与超平面间的距离，直至超平面越过该误分类点使其被正确分类。

###### 对偶形式

原始形式的模型中计算量主要集中在w与x的內积，尤其当x的维度较高时，计算所有样本的分类结果将会变的很慢。通过损失函数计算变量w和b的梯度如下。

$$
\frac{\partial L(w,b)}{\partial w} = - \sum_{x_{i}\in M}y_{i}x_{i}
$$

$$
\frac{\partial L(w,b)}{\partial b} = - \sum_{x_{i}\in M}y_{i}
$$

所以基于随机梯度下降法进行更新时，每次选取一个误分类点(xi, yi)，对w，b更新后的结果如下。

$$
w\leftarrow w+\eta y_{i}x_{i}, b\leftarrow b+\eta y_{i}
$$

若设w,b的初始值均为0，则对上式逐步修改n次后，w,b关于(xi, yi)的增量分别为aiyixi和aiyi，故最终学到的w和b分别表示如下。

$$
w=\sum_{i=1}^{N}\alpha _{i}y_{i}x_{i}, b=\sum_{i=1}^{N}\alpha _{i}y_{i}, \alpha _{i}=n_{i}\eta 
$$

得到**感知机模型的对偶形式**如下。

$$
f(x)=sign(\sum_{j=1}^{N}\alpha _{j}y_{j}x_{j}\cdot x + b)
$$

**对偶形式中训练实例以內积的形式出现，所以可将训练集中的实例间的內积计算并存储在矩阵(Gram)中，这样通过查矩阵即可快速计算出当前样本分类的结果，减少了计算的时间**。其理解过程详见知乎文章：[如何理解感知机学习算法的对偶形式？](https://www.zhihu.com/question/26526858/answer/253579695)

##### K近邻法(k-nearest neighbor, k-NN)

###### 模型及算法

- 概览

是一种基本分类和回归方法，输入为实例的特征向量(特征空间的点)，输出为实例的类别。不具有显示的学习过程，其**直观理解**：给定一个训练数据集，对新的输入实例，在训练集中找到与该实例最近邻的k个实例，这k个实例的多数属于某个类，则该输入实例分为这个类。从中总结出该算法的**三个基本要素为：k值的选择、距离度量和分类决策规则**。

利用训练数据集对特征向量空间进行划分，可看做是训练集中的样本点，将特征空间中距离该点比其他样本点更近的所有点组成一个区域，称之为单元，这样不同单元的类别是确定的，可作为k近邻分类的模型；特征空间中两实例点的距离是其相似程度的反应，可以使用欧式距离，或更一般的Lp距离或Minkowski距离；分类决策规则为多数表决规则。

- 分类决策规则：多数表决

对多数表决规则的理解，假设分类损失为0-1损失函数，则误分类的概率如下。

$$
P(Y\neq f(x)))=1-P(y=f(x))
$$

那么对于训练集中的误分类率，可用如下公式表示。所以误分类率最小等价于将x所属邻域N中最多数的类别c作为x的类别y，即**多数表决规则等价于经验风险最小化**。eg:x的邻域共5个点(N)，2个类别为0，3个类别为1，则<u>区域N的类别c为1</u>，此时y=1时和区域N的类别相同，故可以减少0-1损失函数。

$$
\frac{1}{k}\sum_{x_{i}\in N_{k}(x)}I(y_{i}\neq c_{j})=1-\frac{1}{k}\sum_{x_{i}\in N_{k}(x)}I(y_{i}= c_{j})
$$

###### k近邻法的实现：kd树

- 由来

使用该算法进行预测时，需要快速完成距离计算和k近邻的搜索，最简单的方法是使用线性扫描和距离排序，计算输入实例与每个训练实例的距离并排序，此时若训练集很大，则会很耗时。kd树则用来减少计算 距离的次数，并提高k近邻搜索的效率。

- kd树的构建

**kd树**是对k维空间中的实例点进行存储以便对其快速检索的二叉树。构建过程相当于不断地用垂直于坐标轴的超平面将k维空间进行划分。具体的：以所有训练集中第一维特征的中位数为切分点，利用垂直于第一维坐标的直线将特征空间分为左右两部分，并将该切分点作为*树的根结点*；对深度为j的结点，选择第L维作为切分的坐标轴，其中L=j(modk) + 1，所有训练集中的第L维特征的中位数作为切分点，切分通过切分点并与L维坐标轴垂直的子特征空间，*切分点作为kd树当前的结点*；重复上述过程至两个子区域中没有训练集实例为止。

- kd树的最近邻搜索
1. 在kd树中找到包含目标点x的叶结点：从根结点出发，递归的访问kd树。若x的当前维坐标小于切分点坐标，则移动到左子结点，否则移动到右子结点，直到kd树的叶结点为止

2. 以此叶结点为“当前最近点”

3. 递归的向上回退，在每个结点进行一下操作：a)若当前结点距离目标点x的距离更近，则将其更新为“当前最近点”；b)检查"当前最近点"的兄弟结点对应的区域中是否有更近的点(以目标点为球心，目标点到当前最近点为半径，观察兄弟结点对应的区域中是否有实例点落在该球体内，若有则将其更新为“当前最近点“，并递归的进行最近邻搜索，若无则向上回退)

4. 当回退至根结点时，搜索结束。此时的”当前最近点“即为目标点x的最近邻点。

##### 朴素贝叶斯法

###### 模型及学习策略

基于特征条件独立性假设学习输入/输出的联合概率分布；然后基于此模型，对给定的输入x,利用贝叶斯定理求出后验概率最大的输出y，作为对x分类的结果。

$$
y=argmax_{c_{k}}P(Y=c_{k})\prod _{j}P(X^{(j)}=x^{(j)}|Y=c_{k})
$$

**联合概率分布的学习**：基于训练集学习先验概率(y)分布和条件概率(x|y)分布，条件概率分布有指数级数量的参数(特征每一维可能取值的乘积再乘以先验分布的可能取值)，其估计实际是不可行，所以朴素贝叶斯法对条件概率分布作了独立性假设。

$$
P(X=x|Y=c_{k})=P(X^{(1)}=x^{(1)}, \cdot \cdot \cdot ,X^{(n)}=x^{(n)}|Y=c_{k})\newline
                       =\prod_{j=1}^{n}P(X^{(j)}=x^{(j)}|Y=c_{k})
$$

**策略**：后验概率最大化，等价于期望风险极小化。*<u>朴素贝叶斯法学到的内容是x与y的联合概率分布</u>*，所以对损失函数L(Y,f(X))的期望如下，详见该文[理解过程](https://blog.csdn.net/yaokun2012/article/details/81913129)。

$$
R_{exp}(f) = E[L(Y,f(X))]=\int_{x*y}L(y,f(x))P(x,y)d_{x}d_{y}\newline
=\int_{x*t}L(y,f(x))P(y|x)P(x)d_{x}d_{y}\newline 
=\int_{x}(\int_{y}L(y,f(x))P(y|x)d_{y})P(x)d_{x}
$$

将上式括号括号中的部分表示为H(x)，由于概率值均大于等于0，所以朴素贝叶斯算法的期望风险最小化等价于其条件概率期望的最小化。

$$
R_{exp}(f) = E_{X}\sum_{k=1}^{K}[L(c_{k}, f(x))]P(c_{k}|X)
$$

由于上式中L和P均大于等于0，所以期望风险Rexp最小化只需要对X=x逐个极小化，即

$$
f(x) = argmin_{y \in Y}\sum_{k=1}^{K}L(c_{k},y)P(c_{k}|X=x) \newline
=argmin_{y \in Y}\sum_{k=1}^{K}P(y \neq c_{k}|X=x) \newline
=argmin_{y \in Y}(1 - P(y =  c_{k}|X=x)) \newline
=argmax_{y \in Y}P(y = c_{k}|X=x)
$$

**对期望风险计算过程的理解**：首先损失函数L中每个值的概率为联合概率P(x,y)，其次，此处的条件概率是P(y|x)，而不是训练过程学到的P(x|y)，因为此处是求损失函数的期望，可获得的信息是关于输入变量x的相关值，而非求损失函数(与训练中的参数条件概率P(x|y)相关)，再者是由于概率和损失函数L自身定义(0-1损失)的原因，两个数均为大于等于零的数，所以可对期望风险的最小化等价转换为求x的极小化，接着是对公式中求和符号的解释，关于x的损失为所有取值不为其对应类别ck值的和，又因为条件概率和为1，且y只有两个值(0和1)，所以由上式中的第三行转换为第四行(求和符号消失)，最后由于减法和被减数是固定值的原因，其最小值等价于减数的最大值。

###### 实现算法-极大似然估计&贝叶斯估计

- 极大似然估计

先验概率的极大似然估计如下，其中k表示类别数。

$$
P(Y=c_{k})=\frac{\sum_{i=1}^{N}I(y_{i}=c_{k})}{N}, k=1,2,\cdot \cdot \cdot ,K
$$

条件概率的极大似然估计，其中j表示样本的第j个特征，l为第j个特征的值。

$$
P(X^{(j)}=a_{jl}|Y=c_{k})=\frac{\sum_{i=1}^{N}I(x_{i}^{(j)}=a_{jl},y_{i}=c_{k})}{\sum_{i=1}^{N}I(y_{i}=c_{k})} \newline
j=1,2,\cdot \cdot \cdot ,n; l=1,2,\cdot \cdot \cdot ,S_{j};k=1,2,\cdot \cdot \cdot ,K
$$

- 贝叶斯估计

极大似然估计可能会出现所要估计的概率值为0的情况，此时会影响到后验概率的计算结果，使分类产生误差。解决问题的方法是采用贝叶斯估计，对应的先验概率和条件概率如下。

$$
P_{\lambda }(Y=c_{k})=\frac{\sum_{i=1}^{N}I(y_{i}=c_{k})+\lambda}{N+K\lambda } \newline
P_{\lambda }(X^{j}=a_{jl}|Y=c_{k})= \frac{\sum_{i=1}^{N}I(x_{i}^{j}=a_{jl},y_{i}=c_{k})+\lambda }{\sum_{i=1}^{N}I(y_{i}=c_{k})+S_{j}\lambda}
$$

##### 决策树

###### 模型

可用于分类和回归问题的树形结构。用于分类时，表示基于特征对实例进行分类的过程，该过程可看做if-then规则的集合(互斥且完备)或基于特征空间条件下类空间的条件概率分布。*具体分类过程*是从根结点开始，对实例的某一特征进行测试，根据计算值将其分配到对应子结点上，递归执行该操作至树的叶结点，则该实例属于该叶结点的类别。其中树的子结点表示某种特征对应的一个取值。所以根结点到叶结点的路径可看做一个if-then规则，该路径的内部结点对应的规则的条件，叶结点对应规则的结论；也可看做是将特征空间划分为互不相交的单元或区域，决策树的一条路径对应于划分后的一个单元，决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。

###### 策略和算法

该模型学习的损失函数为正则化的极大似然函数，*学习策略*为以损失函数为目标函数的最小化。

从所有可能的决策树中选取最优决策树是NP完全问题，所以现实中决策树*学习算法*通常采用启发式方法，近似求解这一最优化问题，这样得到的决策树也是次最优的。具体的是递归地选择最优特征，并根据该特征对训练数据进行分割，使得各子数据集有一个最好的分类过程。该过程对应着特征空间的划分，也是构建决策树的过程。这样构建的决策树对训练数据有很好的分类能力，但是对未知的测试数据却未必有很好的分类能力(过拟合现象)，所以需要自下向上对模型进行剪枝，简化模型使其有更好的泛化能力。<u>决策树模型生成时是基于某种特征进行选择的，具有局部性，剪枝时则需要考虑全局最优性</u>。另外，*决策树的深度对应着该模型的复杂度*。

###### 信息增益或信息增益比

特征选择在于选取对训练数据具有分类能力的特征，这样可以提高决策树学习的效率。倘若根据某特征进行分类的结果与随机分类没有很大差别，则该特征是没有分类能力的。所以需要有特征选择的准则：信息增益或信息增益比。

- 信息增益：集合D的经验熵H(D)与给定特征A的条件下D的经验条件熵H(D|A)之差。

$$
g(D,A)=H(D)-H(D|A)
$$

> 熵(entropy)表示随机变量的不确定性，其大小仅与变量的分布有关，与变量取值无关。对随机变量X，对应的熵计算公式如下。
> 
> $$
> H(X)=-\sum_{i=1}^{n}p_{i}log(p_{i})
> $$

> 条件熵H(Y|X)表示给定X条件下Y的条件概率分布的熵对X的数学期望
> 
> $$
> H(Y|X)=\sum_{i=1}^{n}p_{i}H(Y|X=x_{i}), p_{i}=P(X=x_{i})
> $$

> 熵与条件熵之差称为互信息(mutual information)，信息增益等价于训练集中类与特征的互信息。

- 信息增益比：信息增益g(D,A)与训练数据集D关于特征A的值的熵之比。其中n为特征A取值的个数。

$$
g_{R}(D,A)=\frac{g(D,A)}{H_{A}(D)}, 其中H_{A}(D)=-\sum_{i=1}^{n}\frac{\left | D_{i} \right |}{\left | D \right |}log_{2}\frac{\left | D_{i} \right |}{\left | D \right |}
$$

###### 决策树的生成

- ID3算法，其核心是利用信息增益准则选择特征，特征的不同取值作为树的结点。相当于用极大似然法进行概率模型的选择。

> 从根结点开始，对结点计算所有可能特征的信息增益，选择信息增益最大的特征作为结点的特征，由该特征的不同值建立子结点；
> 
> 对子结点递归的调用以上方法，构建决策树；
> 
> 直到所有特征的信息增益均很小或没有特征可以选择为止；
> 
> 生成一个决策树。

-  C4.5算法，不同于ID3算法之处是利用信息增益比来选择特征；

###### 决策树的剪枝

剪枝是对决策树学习中得到的决策树进行简化的过程。用于解决生成算法得到的决策树容易产生过拟合的问题，本质是降低树的复杂度。具体地是通过极小化如下损失函数实现的：递归地从叶结点向上回溯，计算回溯前后的损失函数，若父结点的损失小于子结点的损失，则进行剪枝，将父结点变为新的叶结点。直到所有父节点的损失函数值大于子结点的损失值；

$$
C_{\alpha }(T)=\sum_{t=1}^{\left | T \right |}N_{t}H_{t}(T)+\alpha \left | T \right |
$$

其中，|T|表示叶结点的数量，Nt表示叶结点t的样本数，Ht表示当前结点t上的经验熵，α为控制模型与训练数据的拟合程度和模型复杂度的参数。该参数取较大值时，意味着选择简单的模型，否则意味着更多的考虑模型与训练数据的拟合程度。

###### CART算法

pass

##### 逻辑斯谛回归模型与最大熵模型

逻辑斯谛回归(logistic regression)是统计学习中的经典分类方法;最大熵模型是基于最大熵准则在分类问题上的应用；两者都属于*对数线性模型*。

###### 逻辑斯谛回归模型

设X为连续随机变量，X服从**逻辑斯谛分布**是指X具有下列分布函数和密度函数。其中μ为位置参数，λ为形状参数。分布函数的图像是条S形曲线(sigmoid curve)，该曲线以(μ, 1/2)为中心对称。

$$
F(x)=P(X\leq x)=\frac{1}{1+e^{-\frac{(x-\mu)}{\gamma }}}, \newline
f(x)={F}'(x)=\frac{e^{-\frac{(x-\mu)}{\gamma }}}{\gamma (1+e^{-\frac{(x-\mu)}{\gamma }})^{2}}
$$

- 模型

*二项逻辑斯谛回归模型*是输出为两类的条件概率分布。

$$
P(Y=1|x)=\frac{exp(w\cdot x + b)}{1+exp(w\cdot x + b)} \newline
P(Y=0|x)=\frac{1}{1+exp(w\cdot x + b)}
$$

> 一个事件的几率是指该事件发生的概率与该事件不发生的概率的比值。所以输出Y=1的对数几率是由输入x的线性函数表示的模型，即逻辑斯谛回归模型。

- 策略

构建概率的似然函数，利用极大似然估计法估计模型参数，从而得到逻辑斯谛回归模型。

$$
由概率P(Y=1|x)=\pi (x), P(Y=0|x)=1-\pi (x)可得似然函数为\newline \prod_{i=1}^{N}[\pi (x_{i})]^{y_{i}}[1-\pi (x_{i})]^{1-y_{i}}
$$

- 算法

求解该模型的问题最终转变为以对数似然函数为目标函数的最优化问题，通常采用的是梯度下降法及拟牛顿法。二项逻辑斯谛回归的参数估计方法可推广到多项逻辑斯谛回归。

###### 最大熵模型

> 最大熵原理：认为熵最大的模型是最好的模型，模型首先要满足已有的事实，即约束条件，在没有更多信息的情况下，那些不确定部分都是“等可能的”。等可能性不容易操作，而熵则是一个可优化的指标。

满足所有约束条件的模型集合为

$$
set \equiv \{{P\epsilon \rho |E_{p}(f_{i})=E_{\widetilde{p}(f_{i}), i=1,2,\cdot \cdot \cdot ,n}}\}
$$

条件概率分布P(Y|X)的条件熵为

$$
H(P)=-\sum_{x,y}\widetilde{p}(x)P(y|x)logP(y|x)
$$

则模型集合中条件熵最大的模型为最大熵模型。

- 策略


