## 基础知识

### 数学相关概念

###### 全概率公式

设事件B1、B2、B3…Bn 构成一个完备事件组，即它们两两互不相容，其和为全集；并且P(Bi)大于0，则对任一事件A发生的概率有如下表示。

$$
P(A)=\sum_{i=1}^{n}P(B_{i})P(A|B_{i})
$$

###### 贝叶斯公式

随机事件B<sub>i</sub>发生的情况下，是由原因A引起的概率表示如下。

$$
P(B_{i}|A)=\frac{P(B_{i})P(A|B_{i})}{P(A)}=\frac{P(B_{i})P(A|B_{i})}{\sum_{i=1}^{n}P(B_{i})P(A|B_{i})}
$$

###### 先验概率

根据以往经验和分析得到的概率，**用于执因求果**。如全概率公式中P(Bi)为先验概率，用于求事件A发生的概率。

###### 后验概率

某件事已经发生，想要计算这件事发生的原因是由某个因素引起的概率，**用于知果求因**。如贝叶斯公式中P(Bi|A)为后验概率，用于表示A发生是由Bi事件引起的概率。

###### [ 似然函数](https://zh.wikipedia.org/wiki/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0)

是一种关于[统计模型](https://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B "统计模型")中参数的函数，表示模型参数中的似然性。**似然性**则是用于在已知某些观测所得到的结果时，对有关事物之性质的参数进行估值。可理解为已知事件A发生的条件下，该事物性质的参数是b的可能性。

$$
L(b|A) = \alpha P(A|B=b)
$$

似然函数的重要性不是它的具体取值，而是当参数变化时函数到底变小还是变大

对同一个似然函数，其所代表的模型中，某项参数值具有多种可能，但如果存在一个参数值，使得它的函数值达到最大的话，那么这个值就是该项参数最为“合理”的参数值。 **极大(最大)似然估计**，表示**知果求最可能的原因**

对数函数是严格单增的，所以极大*对数似然*的解与极大似然的解是相同的

###### [先验概率、后验概率、似然函数及贝叶斯公式的理解](https://www.zhihu.com/question/24261751/answer/158547500)

$$
P(B_{i}|A)=\frac{P(B_{i})P(A|B_{i})}{P(A)}=\frac{P(B_{i})P(A|B_{i})}{\sum_{i=1}^{n}P(B_{i})P(A|B_{i})}
$$

贝叶斯公式中P(Bi|A)表示后验概率，P(Bi)表示先验概率，P(A|Bi)表示似然函数中参数是Bi时A的概率，P(A)表示一种事实的概率。

###### 凸集

在凸几何中，凸集(convex set)是在凸组合下闭合的仿射空间的子集。更具体地说，在欧氏空间中，凸集是对于集合内的每一对点，连接这两个点的直线上的每个点也在该集合内。**实数R上（或复数C上）的向量空间中，如果集合S中任两点的连线上的点都在S内，则称集合S为凸集**

###### 凸函数

凸函数是一个定义在某个向量空间的凸子集C上的实值函数f，而且对于凸子集C中任意两个点有如下表达式，其中λ属于(0, 1)区间。

$$
f(\lambda x_{1} + (1-\lambda )x_{2})\leq \lambda f(x_{1}) + (1-\lambda )f(x_{2})
$$

> ps：该定义与高数中的凸函数刚好相反，所以容易混淆。由于机器学习中，通常认为凸函数具有局部最小值即全局最小值的性质，故采用上述定义来描述凸函数。

###### [拉格朗日函数](https://zh.wikipedia.org/wiki/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0)

在数学的最优化问题中，拉格朗日乘数法是一种寻找多元函数在其变量受到一个或多个条件约束时的极值的方法。

###### 仿射函数

若函数f(x)满足f(x)=a\*x + b, 其中a,b,x均为实数域中的值时，则称f(x)为仿射函数。

###### 取正值的函数

$$
\left [ z \right ]_{+}=\left\{\begin{matrix}
z & ,z>0\\ 
0& ,z\leq 0 
\end{matrix}\right.
$$

###### 线性方程

指未知数都是一次的方程，包含两个未知数的一次方程为二元一次方程。其本质是等式两边乘以任何相同的非零数，方程式的解不变。

###### 琴生(Jensen)不等式

基于上述凸函数的形式进行说明(开口向上为凸函数)。f(x)在区间[a,b]上为凸函数，则对于该区间的变量x有如下不等式，等号成立的条件是变量值相等。

$$
f(\frac{x_{1} + x_{2} + \cdot \cdot \cdot + x_{n}}{n})\leq \frac{f(x_{1}) + f(x_{2} + \cdot \cdot \cdot + + f(x_{n})}{n} 

$$

更一般的形式如下。其中变量的系数a均大于0，且和值为1。

$$
f(a_{1}x_{1} + a_{2}x_{2} + \cdot \cdot \cdot + a_{n}x_{n})\leq a_{1}f(x_{1}) + a_{2}f(x_{2}) + \cdot \cdot \cdot + a_{n}f(x_{n})
$$

###### NP(Nondeterministic Polynomially)问题

非确定性多项式问题是指一个复杂问题不能确定是否在多项式时间内找到答案，但是可以在多项式时间内验证答案是否正确。NP类问题很多，如完全子图问题、[图着色问题](https://baike.baidu.com/item/%E5%9B%BE%E7%9D%80%E8%89%B2%E9%97%AE%E9%A2%98)、旅行商([TSP](https://baike.baidu.com/item/TSP/2905216))问题等。

###### 凸优化问题

指有约束条件的最优化问题，如下所示，其中目标函数f(x)和约束函数g(w)都是实数域上连续可微的凸函数，约束函数h(w)为实数域上的仿射函数。若f(x)为二次函数，g(w)为仿射函数时，凸优化问题变为**凸二次规划问题**。

$$
\min\limits_{w}\,f(w) \\
s.t. \, g_{i}(w)\leq 0, \, i=1,2,\cdot \cdot \cdot ,k  \\
h_{i}(w)=0,  i=1,2,\cdot \cdot \cdot ,l 
$$

###### 对偶问题及KKT条件(附录 拉格朗日对偶性)

pass

### 数据结构相关概念

##### [树](https://zh.wikipedia.org/wiki/%E6%A0%91_%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84)

![树的深度与高度图解](D:\Project\MyGithub\dl_Learning-materials\img\Basic_tree.jpg)

                                                            图片来着[这里 ](https://stackoverflow.com/questions/2603692/what-is-the-difference-between-tree-depth-and-height)          

- **深度**：对于任意节点n,n的深度为从根到n的唯一路径长，**根的深度为0**；

- **高度**：对于任意节点n,n的高度为从n到一片树叶的最长路径长，**所有树叶的高度为0**；

- **节点的度**：一个节点含有的子树的个数称为该节点的度；

- **树的度**：一棵树中，最大的节点度称为树的度；

- **叶节点**或**终端节点**：度为零的节点；

- **非终端节点**或**分支节点**：度不为零的节点；

- **父亲节点**或**父节点**：若一个节点含有子节点，则这个节点称为其子节点的父节点；

- **孩子节点**或**子节点**：一个节点含有的子树的根节点称为该节点的子节点；

- **兄弟节点**：具有相同父节点的节点互称为兄弟节点；

- 节点的**层次**：从根开始定义起，根为第1层，根的子节点为第2层，以此类推；

- **堂兄弟节点**：父节点在同一层的节点互为堂兄弟；

- **节点的祖先**：从根到该节点所经分支上的所有节点；

- **子孙**：以某节点为根的子树中任一节点都称为该节点的子孙。

- **森林**：由m（m>=0）棵互不相交的树的集合称为森林；

###### 图

> 图(graph)是由结点(node)及连接结点的边(edge)组成的集合。
> 
> 无向图是指边没有方向的图

### 机器学习相关概念

###### 数据集

> 训练集用于训练模型；
> 
> 验证集用于模型的选择；
> 
> 测试集用于最终对学习方法的评估；

###### 统计学习方法概论

统计学习方法是基于数据构建概率统计模型并运用模型对数据进行预测与分析的学科，由**监督学习**（supervised learning），**非监督学习**，**半监督学习和强化学习**（reinforcement learning）等组成。统计学习方法的三要素如下。

> 模型：所要学习的条件概率分布或决策函数；
> 
> 策略：学习或选择最优模型的准则，即损失函数(度量模型一次预测的好坏)和风险函数(度量平均意义下模型预测的好坏)的构建；(定义损失函数，并将其极小化)
> 
> 算法：学习模型的具体计算方法，即求解最优化问题的算法

###### 生成模型与判别模型

- 定义

> 生成模型：由数据学习联合概率分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型。即模型表示了给定输入X产生输出Y的生成关系；
> 
> 判别模型：由数据直接学习决策函数f(X)或条件概率分布P(Y|X)作为预测模型。即模型表示给定输入X时预测什么样的输出Y；

- 常见模型：

> 生成模型包括朴素贝叶斯法和隐马尔科夫模型；
> 
> 判别模型包括：感知机、k近邻法、决策树、逻辑斯谛回归模型、最大熵模型、支持向量机、提升方法和条件随机场等；

- 优缺点

> 生成方法可还原出联合概率分布P(X,Y);学习收敛速度较判别方法更快；存在隐变量时仍可用生成方法，此时判别方法不可用；
> 
> 判别方法学习的准确率更高；可对数据进行抽象、定义特征并使用特征，简化学习问题。

##### 模型选择

旨在避免过拟合并提高模型的预测能力。**模型选择常用的方法：正则化和交叉验证**。模型对未知数据的预测能力称为**泛化能力**。

> 过拟合 指学习时选择的模型包含的参数过多，以致于出现这一模型对已知数据预测的很好，但对未知数据预测很差的现象

###### 正则化

正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或罚项。正则化项一般是模型复杂度的单调递增函数，如正则化项可以是模型参数向量的范数。

###### 交叉验证

数据充足时，选择对验证集有最小预测误差的模型。否则采用交叉验证的方法，其基本思想是重复的使用数据，把数据分为训练集与测试集，在此基础上反复训练、测试以及模型选择。包括简单交叉验证，S折交叉验证和留一交叉验证。

> 简单交叉验证 将数据切分为训练集(70%)和测试集(30%)，然后用训练集在不同条件下(eg:不同参数个数)训练模型；然后在测试集上评测各模型的测试误差，选择误差最小的模型；
> 
> S折交叉验证 随机将数据切分为S个互不相交大小相同的子集，然后利用S-1个子集作为训练集，剩余的一个作为测试集训练模型。将上述过程对可能的S种集合重复进行，最后选择S次评测中测试误差最小的模型。该方法应用最多；
> 
> 留一交叉验证 S折交叉验证的特殊情况，即S等于样本容量。

###### 泛化能力

通常基于测试误差评价模型的泛化能力，但由于测试集的有限性，导致评测结果是不可靠的。因此使用泛化误差来反应模型的泛化能力。

###### 希尔伯特空间

一个內积空间，当作为一个赋范向量空间是完备的时候，就是希尔伯特空间

> 向量空间：对加法和数乘运算是封闭的集合称之为向量空间
> 
> 內积空间：赋予內积的向量空间称之为內积空间
> 
> 赋范向量空间：由內积空间可以得到范数，如下式子所示。称之为赋范向量空间。
> 
> $$
> \left \| f \right \|=\sqrt{f\cdot f}
> $$
> 
> 根据泛函分析理论，对于不完备的赋范向量空间，一定可以使之完备化，得到完备的赋范向量空间，即希尔伯特空间

### 评价指标

##### 分类问题

pass

### 距离度量函数

##### Lp距离

向量xi与xj的Lp距离定义如下，其中p>=1。当p=2时称为**欧式距离**(Euclidean distance)，当p=1时为**曼哈顿距离**(Manhattan distance)

$$
L_{p}(x_{i}, x_{j})=\left ( \sum_{l=1}^{n}\left | x_{i}^{(l)} - x_{j}^{(l)} \right |^{p} \right )^{\frac{1}{p}}
$$

##### 函数汇总

- 符号函数

$$
sign(x)=\left\{\begin{matrix}
+1,  x\geq 0 & \\ 
-1,  x< 0& 
\end{matrix}\right.
$$

- 指示函数，表示其中有哪些元素属于某一子集*A*。

$$
I_{A}(x)=\left\{\begin{matrix}
1 & \\ 
0 & 
\end{matrix}\right.  \begin{matrix}
x \in A& \\ 
x \not\in A& 
\end{matrix}
$$

- argmax, 表示求函数最大值的参数的函数
  
  > y = max f(t) 代表：y 是f(t)函式所有的值中最大的output。
  > 
  > y = argmax f(t) 代表：y 是f(t)函式中，会产生最大output的那个参数t。

## 机器学习方法—李航《统计学习方法》

##### 感知机

###### 原始形式

- 二分类的线性分类模型，输入为实例的特征向量，输出为实例的类别。**感知机模型为激活函数是符号函数的神经元**，是神经网络与支持向量机的基础。

$$
f(x)=sign(w\cdot x +b)
$$

- 学习策略为经验风险函数极小化，用于表示所有误分类点(集合M)到分类超平面的距离和(不考虑超平面的模值1/|w|)。*这种基于误分类最小策略获得的超平面有无穷多个*

$$
L(w,b)=-\sum_{x_{i}\varepsilon M}y_{i}(w\cdot x_{i}+b)
$$

- 算法是误分类数据驱动的，采用随机梯度下降法(stochastic gradient descent)。首先，任选一个超平面w0,b0，然后用梯度下降法不断极小化目标函数。极小化过程中每次随机选取一个误分类点使其梯度下降。

> 直观理解是当一个实例点被误分类时，调整w,b的值，使分离超平面向该误分类点的一侧移动，以减少误分类点与超平面间的距离，直至超平面越过该误分类点使其被正确分类。

###### 对偶形式

原始形式的模型中计算量主要集中在w与x的內积，尤其当x的维度较高时，计算所有样本的分类结果将会变的很慢。通过损失函数计算变量w和b的梯度如下。

$$
\frac{\partial L(w,b)}{\partial w} = - \sum_{x_{i}\in M}y_{i}x_{i}
$$

$$
\frac{\partial L(w,b)}{\partial b} = - \sum_{x_{i}\in M}y_{i}
$$

所以基于随机梯度下降法进行更新时，每次选取一个误分类点(xi, yi)，对w，b更新后的结果如下。

$$
w\leftarrow w+\eta y_{i}x_{i}, b\leftarrow b+\eta y_{i}
$$

若设w,b的初始值均为0，则对上式逐步修改n次后，w,b关于(x<sub>i</sub>, y<sub>i</sub>)的增量分别为a<sub>i</sub>y<sub>i</sub>x<sub>i</sub>和a<sub>i</sub>y<sub>i</sub>，故最终学到的w和b分别表示如下。

$$
w=\sum_{i=1}^{N}\alpha _{i}y_{i}x_{i}, b=\sum_{i=1}^{N}\alpha _{i}y_{i}, \alpha _{i}=n_{i}\eta 
$$

得到**感知机模型的对偶形式**如下。

$$
f(x)=sign(\sum_{j=1}^{N}\alpha _{j}y_{j}x_{j}\cdot x + b)
$$

**对偶形式中训练实例以內积的形式出现，所以可将训练集中的实例间的內积计算并存储在矩阵(Gram)中，这样通过查矩阵即可快速计算出当前样本分类的结果，减少了计算的时间**。其理解过程详见知乎文章：[如何理解感知机学习算法的对偶形式？](https://www.zhihu.com/question/26526858/answer/253579695)

##### K近邻法(k-nearest neighbor, k-NN)

###### 模型及算法

- 概览

是一种基本分类和回归方法，输入为实例的特征向量(特征空间的点)，输出为实例的类别。不具有显示的学习过程，其**直观理解**：给定一个训练数据集，对新的输入实例，在训练集中找到与该实例最近邻的k个实例，这k个实例的多数属于某个类，则该输入实例分为这个类。从中总结出该算法的**三个基本要素为：k值的选择、距离度量和分类决策规则**。

利用训练数据集对特征向量空间进行划分，可看做是训练集中的样本点，将特征空间中距离该点比其他样本点更近的所有点组成一个区域，称之为单元，这样不同单元的类别是确定的，可作为k近邻分类的模型；特征空间中两实例点的距离是其相似程度的反应，可以使用欧式距离，或更一般的Lp距离或Minkowski距离；分类决策规则为多数表决规则。

- 分类决策规则：多数表决

对多数表决规则的理解，假设分类损失为0-1损失函数，则误分类的概率如下。

$$
P(Y\neq f(x)))=1-P(y=f(x))
$$

那么对于训练集中的误分类率，可用如下公式表示。所以误分类率最小等价于将x所属邻域N中最多数的类别c作为x的类别y，即**多数表决规则等价于经验风险最小化**。eg:x的邻域共5个点(N)，2个类别为0，3个类别为1，则<u>区域N的类别c为1</u>，此时y=1时和区域N的类别相同，故可以减少0-1损失函数。

$$
\frac{1}{k}\sum_{x_{i}\in N_{k}(x)}I(y_{i}\neq c_{j})=1-\frac{1}{k}\sum_{x_{i}\in N_{k}(x)}I(y_{i}= c_{j})
$$

###### k近邻法的实现：kd树

- 由来

使用该算法进行预测时，需要快速完成距离计算和k近邻的搜索，最简单的方法是使用线性扫描和距离排序，计算输入实例与每个训练实例的距离并排序，此时若训练集很大，则会很耗时。kd树则用来减少计算 距离的次数，并提高k近邻搜索的效率。

- kd树的构建

**kd树**是对k维空间中的实例点进行存储以便对其快速检索的二叉树。构建过程相当于不断地用垂直于坐标轴的超平面将k维空间进行划分。具体的：以所有训练集中第一维特征的中位数为切分点，利用垂直于第一维坐标的直线将特征空间分为左右两部分，并将该切分点作为*树的根结点*；对深度为j的结点，选择第L维作为切分的坐标轴，其中L=j(mod)k + 1，所有训练集中的第L维特征的中位数作为切分点，切分通过切分点并与L维坐标轴垂直的子特征空间，*切分点作为kd树当前的结点*；重复上述过程至两个子区域中没有训练集实例为止。

- kd树的最近邻搜索
1. 在kd树中找到包含目标点x的叶结点：从根结点出发，递归的访问kd树。若x的当前维坐标小于切分点坐标，则移动到左子结点，否则移动到右子结点，直到kd树的叶结点为止

2. 以此叶结点为“当前最近点”

3. 递归的向上回退，在每个结点进行以下操作：a)若当前结点距离目标点x的距离更近，则将其更新为“当前最近点”；b)检查"当前最近点"的兄弟结点对应的区域中是否有更近的点(以目标点为球心，目标点到当前最近点为半径，观察兄弟结点对应的区域中是否有实例点落在该球体内，若有则将其更新为“当前最近点“，并递归的进行最近邻搜索，若无则向上回退)

4. 当回退至根结点时，搜索结束。此时的”当前最近点“即为目标点x的最近邻点。

##### 朴素贝叶斯法

###### 模型及学习策略

基于特征条件独立性假设学习输入/输出的联合概率分布；然后基于此模型，对给定的输入x,利用贝叶斯定理求出后验概率最大的输出y，作为对x分类的结果。

$$
y=argmax_{c_{k}}P(Y=c_{k})\prod _{j}P(X^{(j)}=x^{(j)}|Y=c_{k})
$$

**联合概率分布的学习**：基于训练集学习先验概率(y)分布和条件概率(x|y)分布，条件概率分布有指数级数量的参数(特征每一维可能取值的乘积再乘以先验分布的可能取值)，其估计实际是不可行，所以朴素贝叶斯法对条件概率分布作了独立性假设。

$$
P(X=x|Y=c_{k})=P(X^{(1)}=x^{(1)}, \cdot \cdot \cdot ,X^{(n)}=x^{(n)}|Y=c_{k})\newline
                       =\prod_{j=1}^{n}P(X^{(j)}=x^{(j)}|Y=c_{k})
$$

**策略**：后验概率最大化，等价于期望风险极小化。*<u>朴素贝叶斯法学到的内容是x与y的联合概率分布</u>*，所以对损失函数L(Y,f(X))的期望如下，详见该文[理解过程](https://blog.csdn.net/yaokun2012/article/details/81913129)。

$$
R_{exp}(f) = E[L(Y,f(X))]=\int_{x*y}L(y,f(x))P(x,y)d_{x}d_{y}\newline
=\int_{x*t}L(y,f(x))P(y|x)P(x)d_{x}d_{y}\newline 
=\int_{x}(\int_{y}L(y,f(x))P(y|x)d_{y})P(x)d_{x}
$$

将上式括号括号中的部分表示为H(x)，由于概率值均大于等于0，所以朴素贝叶斯算法的期望风险最小化等价于其条件概率期望的最小化。

$$
R_{exp}(f) = E_{X}\sum_{k=1}^{K}[L(c_{k}, f(x))]P(c_{k}|X)
$$

由于上式中L和P均大于等于0，所以期望风险Rexp最小化只需要对X=x逐个极小化，即

$$
f(x) = argmin_{y \in Y}\sum_{k=1}^{K}L(c_{k},y)P(c_{k}|X=x) \newline
=argmin_{y \in Y}\sum_{k=1}^{K}P(y \neq c_{k}|X=x) \newline
=argmin_{y \in Y}(1 - P(y =  c_{k}|X=x)) \newline
=argmax_{y \in Y}P(y = c_{k}|X=x)
$$

**对期望风险计算过程的理解**：首先损失函数L中每个值的概率为联合概率P(x,y)，其次，此处的条件概率是P(y|x)，而不是训练过程学到的P(x|y)，因为此处是求损失函数的期望，可获得的信息是关于输入变量x的相关值，而非求损失函数(与训练中的参数条件概率P(x|y)相关)，再者是由于概率和损失函数L自身定义(0-1损失)的原因，两个数均为大于等于零的数，所以可对期望风险的最小化等价转换为求x的极小化，接着是对公式中求和符号的解释，关于x的损失为所有取值不为其对应类别ck值的和，又因为条件概率和为1，且y只有两个值(0和1)，所以由上式中的第三行转换为第四行(求和符号消失)，最后由于减法和被减数是固定值的原因，其最小值等价于减数的最大值。

###### 实现算法-极大似然估计&贝叶斯估计

- 极大似然估计

先验概率的极大似然估计如下，其中k表示类别数。

$$
P(Y=c_{k})=\frac{\sum_{i=1}^{N}I(y_{i}=c_{k})}{N}, k=1,2,\cdot \cdot \cdot ,K
$$

条件概率的极大似然估计，其中j表示样本的第j个特征，l为第j个特征的值。

$$
P(X^{(j)}=a_{jl}|Y=c_{k})=\frac{\sum_{i=1}^{N}I(x_{i}^{(j)}=a_{jl},y_{i}=c_{k})}{\sum_{i=1}^{N}I(y_{i}=c_{k})} \newline
j=1,2,\cdot \cdot \cdot ,n; l=1,2,\cdot \cdot \cdot ,S_{j};k=1,2,\cdot \cdot \cdot ,K
$$

- 贝叶斯估计

极大似然估计可能会出现所要估计的概率值为0的情况，此时会影响到后验概率的计算结果，使分类产生误差。解决问题的方法是采用贝叶斯估计，对应的先验概率和条件概率如下。

$$
P_{\lambda }(Y=c_{k})=\frac{\sum_{i=1}^{N}I(y_{i}=c_{k})+\lambda}{N+K\lambda } \newline
P_{\lambda }(X^{j}=a_{jl}|Y=c_{k})= \frac{\sum_{i=1}^{N}I(x_{i}^{j}=a_{jl},y_{i}=c_{k})+\lambda }{\sum_{i=1}^{N}I(y_{i}=c_{k})+S_{j}\lambda}
$$

##### 决策树

###### 模型

可用于分类和回归问题的树形结构。用于分类时，表示基于特征对实例进行分类的过程，该过程可看做if-then规则的集合(互斥且完备)或基于特征空间条件下类空间的条件概率分布。*具体分类过程*是从根结点开始，对实例的某一特征进行测试，根据计算值将其分配到对应子结点上，递归执行该操作至树的叶结点，则该实例属于该叶结点的类别。其中树的子结点表示某种特征对应的一个取值。所以根结点到叶结点的路径可看做一个if-then规则，该路径的内部结点对应的规则的条件，叶结点对应规则的结论；也可看做是将特征空间划分为互不相交的单元或区域，决策树的一条路径对应于划分后的一个单元，决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。

###### 策略和算法

该模型学习的损失函数为正则化的极大似然函数，*学习策略*为以损失函数为目标函数的最小化。

从所有可能的决策树中选取最优决策树是NP完全问题，所以现实中决策树*学习算法*通常采用启发式方法，近似求解这一最优化问题，这样得到的决策树也是次最优的。具体的是递归地选择最优特征，并根据该特征对训练数据进行分割，使得各子数据集有一个最好的分类过程。该过程对应着特征空间的划分，也是构建决策树的过程。这样构建的决策树对训练数据有很好的分类能力，但是对未知的测试数据却未必有很好的分类能力(过拟合现象)，所以需要自下向上对模型进行剪枝，简化模型使其有更好的泛化能力。<u>决策树模型生成时是基于某种特征进行选择的，具有局部性，剪枝时则需要考虑全局最优性</u>。另外，*决策树的深度对应着该模型的复杂度*。

###### 信息增益或信息增益比

特征选择在于选取对训练数据具有分类能力的特征，这样可以提高决策树学习的效率。倘若根据某特征进行分类的结果与随机分类没有很大差别，则该特征是没有分类能力的。所以需要有特征选择的准则：信息增益或信息增益比。

- 信息增益：集合D的经验熵H(D)与给定特征A的条件下D的经验条件熵H(D|A)之差。

$$
g(D,A)=H(D)-H(D|A)
$$

> 熵(entropy)表示随机变量的不确定性，其大小仅与变量的分布有关，与变量取值无关。对随机变量X，对应的熵计算公式如下。
> 
> $$
> H(X)=-\sum_{i=1}^{n}p_{i}log(p_{i})
> $$

> 条件熵H(Y|X)表示给定X条件下Y的条件概率分布的熵对X的数学期望
> 
> $$
> H(Y|X)=\sum_{i=1}^{n}p_{i}H(Y|X=x_{i}), p_{i}=P(X=x_{i})
> $$

> 熵与条件熵之差称为互信息(mutual information)，信息增益等价于训练集中类与特征的互信息。

- 信息增益比：信息增益g(D,A)与训练数据集D关于特征A的值的熵之比。其中n为特征A取值的个数。

$$
g_{R}(D,A)=\frac{g(D,A)}{H_{A}(D)}, 其中H_{A}(D)=-\sum_{i=1}^{n}\frac{\left | D_{i} \right |}{\left | D \right |}log_{2}\frac{\left | D_{i} \right |}{\left | D \right |}
$$

###### 决策树的生成

- ID3算法，其核心是利用信息增益准则选择特征，特征的不同取值作为树的结点。相当于用极大似然法进行概率模型的选择。

> 从根结点开始，对结点计算所有可能特征的信息增益，选择信息增益最大的特征作为结点的特征，由该特征的不同值建立子结点；
> 
> 对子结点递归的调用以上方法，构建决策树；
> 
> 直到所有特征的信息增益均很小或没有特征可以选择为止；
> 
> 生成一个决策树。

-  C4.5算法，不同于ID3算法之处是利用信息增益比来选择特征；

###### 决策树的剪枝

剪枝是对决策树学习中得到的决策树进行简化的过程。用于解决生成算法得到的决策树容易产生过拟合的问题，本质是降低树的复杂度。具体地是通过极小化如下损失函数实现的：递归地从叶结点向上回溯，计算回溯前后的损失函数，若父结点的损失小于子结点的损失，则进行剪枝，将父结点变为新的叶结点。直到所有父节点的损失函数值大于子结点的损失值；

$$
C_{\alpha }(T)=\sum_{t=1}^{\left | T \right |}N_{t}H_{t}(T)+\alpha \left | T \right |
$$

其中，|T|表示叶结点的数量，Nt表示叶结点t的样本数，Ht表示当前结点t上的经验熵，**α为控制模型与训练数据的拟合程度和模型复杂度的参数**。该参数取较大值时，意味着选择简单的模型，否则意味着更多的考虑模型与训练数据的拟合程度。

###### CART算法

pass

##### 逻辑斯谛回归模型与最大熵模型

逻辑斯谛回归(logistic regression)是统计学习中的经典分类方法;最大熵模型是基于最大熵准则在分类问题上的应用；两者都属于*对数线性模型*。

###### 逻辑斯谛回归模型

设X为连续随机变量，X服从**逻辑斯谛分布**是指X具有下列分布函数和密度函数。其中μ为位置参数，λ为形状参数。分布函数的图像是条S形曲线(sigmoid curve)，该曲线以(μ, 1/2)为中心对称。

$$
F(x)=P(X\leq x)=\frac{1}{1+e^{-\frac{(x-\mu)}{\gamma }}}, \newline
f(x)={F}'(x)=\frac{e^{-\frac{(x-\mu)}{\gamma }}}{\gamma (1+e^{-\frac{(x-\mu)}{\gamma }})^{2}}
$$

- 模型

*二项逻辑斯谛回归模型*是输出为两类的条件概率分布。

$$
P(Y=1|x)=\frac{exp(w\cdot x + b)}{1+exp(w\cdot x + b)} \newline
P(Y=0|x)=\frac{1}{1+exp(w\cdot x + b)}
$$

> 一个事件的几率是指该事件发生的概率与该事件不发生的概率的比值。所以输出Y=1的对数几率是由输入x的线性函数表示的模型，即逻辑斯谛回归模型。

- 策略

构建概率的似然函数，利用极大似然估计法估计模型参数，从而得到逻辑斯谛回归模型。

$$
由概率P(Y=1|x)=\pi (x), P(Y=0|x)=1-\pi (x)可得似然函数为\newline \prod_{i=1}^{N}[\pi (x_{i})]^{y_{i}}[1-\pi (x_{i})]^{1-y_{i}}
$$

- 算法

求解该模型的问题最终转变为以对数似然函数为目标函数的最优化问题，通常采用的是梯度下降法及拟牛顿法。二项逻辑斯谛回归的参数估计方法可推广到多项逻辑斯谛回归。

###### 最大熵模型

> 最大熵原理：认为熵最大的模型是最好的模型，模型首先要满足已有的事实，即约束条件，在没有更多信息的情况下，那些不确定部分都是“等可能的”。等可能性不容易操作，而熵则是一个可优化的指标。

满足所有约束条件的模型集合为

$$
set \equiv \{P\epsilon \rho |E_{p}(f_{i})=E_{\widetilde{p}}(f_{i}), i=1,2,\cdot \cdot \cdot ,n\}
$$

条件概率分布P(Y|X)的条件熵为

$$
H(P)=-\sum_{x,y}{\widetilde{p}(x)}P(y|x)logP(y|x)
$$

则模型集合中条件熵最大的模型为最大熵模型，具体为如下条件概率分布表示的分类模型，其中f为特征函数，w为对应函数的权重。可用于二分类或多分类。

$$
P_{w}（y|x）=\frac{1}{Z_{w}(x)}exp(\sum_{i=1}^{n}w_{i}f_{i}(x,y)), \newline
Z_{w}(x)=\sum_{y}exp(\sum_{i=1}^{n}w_{i}f_{i}(x,y))
$$

- 策略 ——形式化为具有约束条件的最优化问题

$$
\max\limits_{P \epsilon set} H(P)=-\sum_{x,y}\widetilde{p}(x)P(y|x)logP(y|x) \newline
s.t. \> E_{p}(f_{i})=E_{\widetilde{p}}(f_{i}), i=1,2,\cdot \cdot \cdot ,n \newline
\sum_{y}P(y|x)=1
$$

pass  （对偶问题求解）

对偶函数的极大化等价于最大熵模型的极大似然估计

- 算法——最优化算法
1. 改进的迭代尺度法
   
   > pass

2. 拟牛顿法
   
   > pass

##### 支持向量机

SVM(support vector machines)是一种二分类模型，**基本模型**是定义在特征空间上间隔最大的线性分类器，间隔最大使其有别于感知机；学习**策略**是间隔最大化，可形式化为求解凸二次规划(convex quadratic programming)的问题，也等价于正则化的合页损失函数的最小化；学习**算法**是求解凸二次规划的最优化算法。

> 线性可分支持向量机(linear support vector machine in linearly separable case)，又称硬间隔支持向量机，主要用于线性可分的数据；
> 
> 线性支持向量机(linear support vector machine)，又称软间隔支持向量机，用于数据近似线性可分的情况；
> 
> 非线性支持向量机(non-inear support vector machine)通过核技巧(kernel trick)和软间隔最大化学习非线性数据；

###### 线性可分支持向量机与硬间隔最大化

> 线性可分情况下，**支持向量**(support vector)是指 训练集中的样本点与分离超平面距离最近的样本点的实例。在确定分离超平面中起着决定性作用，所以该分类模型称为支持向量机。
> 
> 点到超平面的距离可表示分类预测的确信程度，故对于超平面w\*x+b=0而言，|w*x+b|表示点x距离超平面的远近，而w\*x +b的符号与类标记y的符号是否一致表示分类是否正确。
> 
> **函数间隔**，超平面关于样本点(xi, yi)的函数间隔如下。超平面(w,b)关于训练集T的函数间隔为T中所有样本点 的函数间隔的最小值。
> 
> $$
> \hat{\gamma}_{i}=y_{i}(w\cdot x_{i}+b) 
> $$

> **几何间隔**，对于成比例修改超平面参数时，如变为2w和2b，此时超平面没改变，函数间隔变为原来的2倍。几何间隔通过对法向量w进行约束，使间隔固定下来。同样，超平面(w,b)关于训练集T的几何间隔为T中所有样本点 的几何间隔的最小值。
> 
> $$
> \gamma_{i}=y_{i}(\frac{w}{\left \| w \right \|}\cdot x_{i}+\frac{b}{\left \| w \right \|})
> $$

> **函数间隔与几何间隔的关系**，由定义公式可得，对训练集T而言，两者的关系如下。
> 
> $$
> \gamma = \frac{\hat{\gamma}}{\left \| w \right \|}
> $$

- 模型——线性超平面。

$$
w\cdot x + b=0
$$

- 策略——间隔最大化。此处间隔指样本点到超平面的几何间隔。对线性可分支持向量机而言，间隔最大化又称为硬间隔最大化。

> 直观解释是对训练集而言，超平面不仅需要将正负实例点分开，而且对最难分的实例点(离超平面最近的点)有足够大的确信度将其分开。

- 算法——凸二次规划。根据几何间隔和函数间隔的关系及法向量范数的等价变换，最终对学习策略的实现过程是以函数间隔为约束条件的凸二次规划问题。

> 几何间隔最大的分离超平面可表示为如下的约束最优化问题。
> 
> $$
> \max\limits_{w,b} \,\gamma \\
> s.t. \, y_{i}(\frac{w}{\left \| w \right \|}\cdot x_{i}+\frac{b}{\left \| w \right \|})\geq \gamma , i=1,2,\cdot \cdot \cdot ,N
> $$

> 由几何间隔与函数间隔的定义式关系可知，当函数间隔设置为1时，可将上述最优化问题转变为如下表达式(为方便后续算法计算，将最大化表达式替换为等价的最小化表达式)。得到一个使用函数间隔作为约束条件的凸二次规划(convex quadratic programming)问题。
> 
> $$
> \min\limits_{w,b} \,\frac{1}{2} \left \| w \right \|^{2}\\
> s.t. \, y_{i}(w\cdot x_{i}+b) - 1\geq 0 , i=1,2,\cdot \cdot \cdot ,N
> 
> $$

###### 最大间隔分离超平面的存在唯一性

pass

###### 对偶算法

pass

###### 线性支持向量机与软间隔最大化

> 数据集不是线性可分的，且满足其中存在一些特异点(outlier)，将特异点除去后，剩下大部分的样本点组成的集合是线性可分的。**软间隔的支持向量**为其学习策略中对偶问题大于0的解所对应的样本点，在其分类超平面上存在于3个位置：间隔边界上(下图虚线部分)、间隔边界与分离超平面间、分离超平面误分的一侧。![的一侧。](D:\Project\MyGithub\dl_Learning-materials\img\Basic_svm.png)

- 模型——同线性可分支持向量机的超平面

- 策略——软间隔最大化，是相对于硬间隔最大化而言的，指样本点的函数间隔需要增加松弛变量后才能满足硬间隔最大化的的条件(大于等于1)。

- 算法——凸二次规划

> 由于数据集中样本点的函数间隔无法满足硬间隔最大化的条件，故为每个样本点增加一个松弛变量使其变换后的函数间隔大于等于1，即约束条件变为
> 
> $$
> y_{i}(w\cdot x_{i}+b) \geq 1-\xi _{i}
> $$
> 
> 同时，目标函数也更新为如下形式，其中**C>0，称为惩罚参数**，C值大时意味着更关心模型误分类点的个数，使其尽可能少。C值较小时更多的是使函数间隔尽可能小。
> 
> $$
> \frac{1}{2} \left \| w \right \|^{2} + C\sum_{i=1}^{N}\xi _{i}
> $$

> 故该模型的学习策略为如下凸二次规划(convex quadratic programming)问题。针对该优化问题的解中w是唯一的，b的解存在于一个区间中，是不唯一的。
> 
> $$
> \min \limits_{w,b,\xi} \, \frac{1}{2} \left \| w \right \|^{2} + C\sum_{i=1}^{N}\xi _{i} \\
> s.t. \, y_{i}(w\cdot x_{i}+b) \geq 1-\xi _{i}, i=1,2,\cdot \cdot \cdot ,N \\
> \xi _{i}\geq 0, i=1,2,\cdot \cdot \cdot ,N
> $$

- 对偶算法

pass

- 策略2 ——正则化的合页损失函数，其中第一项为经验损失， 第二项为正则化项。经验损失中，待求和的函数L(y(w\*x+b))因其形状像门窗的合页，故称为合页损失函数(hinge loss function)。

$$
\sum_{i=1}^{N} \left [ 1 - y_{i}(w\cdot x_{i}+b) \right ]_{+} + \gamma \left \| w \right \|^{2}, i=1,2,\cdot \cdot \cdot ,N \\

$$

- 凸二次规划等价于正则化的合页损失函数

pass

###### 非线性支持向量机与核函数

> 非线性可分问题：实数空间中存在超曲面可以将正负实例分开，则称之为非线性可分问题。

- 核函数(kernel function)

> 输入空间为欧式空间或离散集合、特征空间为希尔伯特空间时，核函数表示将输入从输入空间映射到特征空间后得到的特征向量之间的內积。基于核函数处理后相当于隐式地在高维特征空间中学习线性支持向量机。这样的技巧称为**核技巧(核方法)**，其基本思想是学习和预测中只定义核函数，而不显示的定义输入空间到特征空间的映射关系， 具体的是将线性支持向量机对偶问题中目标函数和决策函数所包含的输入实例间的內积使用核函数来替代。它是一种巧妙的利用线性分类学习方法与核函数来解决非线性问题的技术。实际使用中，往往依赖领域知识直接选择核函数，核函数的有效性需要通过实验验证。核技巧是比支持向量机更一般的机器学习方法。
> 
> $$
> K(x,z)=\phi (x)\cdot \phi (z)
> $$
> 
> K(x,z)为**核函数**，Φ(x)为输入空间到特征空间的映射函数，等式的右边为映射函数的內积。**对于给定的核函数，特征空间和映射函数的取法不唯一，可以取不同的特征空间，即便是在同一特征空间里也可以取不同的映射。**·

- 正定核

> 通常所说的核函数就是正定核函数
> 
> **本节主要描述函数满足什么条件时才能成为核函数** 
> 
> 正定核函数的充要条件：设K:Χ✖Χ →R是对称函数，则K(x,z)为正定核的充要条件是对x中任意的元素，K(x,z)对应的Gram矩阵(如下)为半正定矩阵。
> 
> $$
> K=\left [ K(x_{i},x_{j}) \right ]_{m\times m}
> $$
> 
> 对具体函数K(x,z)而言，实际使用中需要对任意有限输入集验证K对应的Gram矩阵是否为半正定，因此检验它是否为正定核函数并不容易。故实际问题中往往应用已有的核函数。

- 常见核函数

> 1. 多项式核函数(polynomial kernel function)
> 
> $$
> k(x,z)=(x\cdot z+1)^{p}
> $$
> 
> 对应的分类决策函数为：
> 
> $$
> f(x)=sign\left ( \sum_{i=1}^{N_{s}}a_{i}^{*}y_{i}(x_{i}\cdot x+1)^{p} + b^{*} \right )
> $$
> 
> 2. 高斯核函数(Gaussian kernel function)
> 
> $$
> K(x,z)=exp(-\frac{\left \| x-z \right \|^{2}}{2\sigma ^{2}})
> $$
> 
>   对应的分类决策核函数为
> 
> $$
> f(x)=sign\left ( \sum_{i=1}^{N_{s}} a_{i}^{*}y_{i}exp\left ( -\frac{\left \| x_{i}-x \right \|^{2}}{2\sigma ^{2}} \right )+b^{*}\right )
> $$
> 
> 3. 字符串核函数(string kernel function)，表示字符串s和t中长度等于n的所有子串组成的特征向量的余弦相似度。s和t中相同的子串越多，它们就越相似，字符串核函数的值就越大。该核函数可由动态规划快速地计算。
> 
> $$
> k_{n}(s,t)=\sum_{u\in\sum^{n}}\left [ \Phi _{n}(s) \right ]_{u}\left [ \Phi _{n}(t) \right ]_{u}=\sum_{u\in\sum^{n}}\sum_{(i,j):s(i)=t(j)=u}\lambda ^{l(i)}\lambda ^{l(j)}
> $$

- 算法——凸二次规划问题

基于核函数构造如下的最优化问题，当K(x,z)是正定核函数时，该优化问题变为凸二次规划问题。

$$
\min_{\alpha }\: \frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha _{i} \alpha _{j}y_{i}y_{j}K(x_{i}, x_{j})-\sum_{i=1}^{N}\alpha _{i} \newline
s.t. \sum_{i=1}^{N}\alpha _{i}y_{i}=0, \newline
0\leq \alpha _{i}\leq C, i=1,2,\cdot \cdot \cdot ,N
$$

###### 序列最小最优化算法

pass

##### 提升方法

通过改变训练样本的权重，学习多个分类器，并将这些分类器进行线性组合，提高分类性能。具有代表性的算法为AdaBoost算法。

> 基本思想：对于复杂任务，将多个专家的判断进行适当的综合所得出的判断，比其中任何一个专家单独的判断好。
> 
> 理论支撑：在PAC(probably approximately correct)学习的框架下，一个概念是强可学习的充要条件是这个概念是弱可学习的。
> 
> PAC：概率近似正确
> 
> 强可学习：在PAC框架中，一个类，若存在一个多项式的学习算法能够学习它，并且准确率很高，则称该类为强可学习的
> 
> 弱可学习：若存在一个多项式的学习算法能够学习它，学习的准确率仅比随机猜测略好，则称该类为弱可学习的。
> 
> 两个核心问题：每一轮如何改变样本的权值或概率分布；如何将多个弱分类器组合为一个强分类器

###### AdaBoost算法

> 修改样本权重的策略：提高被前一轮弱分类器错误分类样本的权值
> 
> 分类器组合的策略：加权多数表决的方法。加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用。

- 模型——弱分类器的线性组合

$$
f(x)=\sum_{m=1}^{M}\alpha _{m}G_{m}(x)
$$

- 算法

> 1. 初始化每个样本的权重。
> 
> $$
> D_{1}=(w_{11},\cdot \cdot \cdot ,w_{1i}, \cdot \cdot \cdot ,w_{1N}), w_{1i}=\frac{1}{N}, i=1,2,\cdot \cdot \cdot ,N
> $$
> 
> 2. 对于每轮训练m=1,2,...,M，(不确定训练次数)。
> 
>     a). 使用具有权值分布Dm的训练数据集进行学习，得到基本分类器
> 
> $$
> G_{m}(x):\chi \rightarrow \left \{ -1, +1 \right \}
> $$
> 
>     b). 计算当前分类器Gm(x)在训练集上的分类误差率。
> 
> $$
> e_{m}=P(G_{m(x_{i}\neq y_{i})})=\sum_{i=1}^{N}w_{mi}I(G_m(x_{i}\neq y_{i}))
> $$
> 
>     c). 计算当前分类器Gm(x) 的系数。用来表示当前分类器的重要性。当误差率小于等于0.5时，系数值大于等于0，并且系数值随着误差率的减小而增大。
> 
> $$
> \alpha _{m}=\frac{1}{2}log\frac{1-e_{m}}{e_{m}}
> $$
> 
>     d). 更新训练集中样本的权值分布。每轮训练中样本权值和为1.不同样本分类对错的不同导致下轮训练时权重的不均匀变化。
> 
> $$
> D_{m+1}=(w_{m+1,1}, \cdot \cdot \cdot ,w_{m+1,i}, \cdot \cdot \cdot ,w_{m+1,N}) \newline
> w_{m+1,i}=\frac{w_{mi}}{Z_{m}}exp(-\alpha _{m}y_{i}G_{m}(x_{i})), \: i=1,2,\cdot \cdot \cdot ,N \newline
> Z_{m}=\sum_{i=1}^{N}w_{mi}exp(-\alpha _{m}y_{i}G_{m}(x_{i}))  
> $$
> 
> 3. 构建分类器的线性组合。值大小表示置信度，符号表示实例x的类别。
> 
> $$
> f(x)=\sum_{m=1}^{M}\alpha _{m}G_{m}(x)
> $$
> 
> 得到最终分类器。
> 
> $$
> G(x)=sign(f(x))=sign(\sum_{m=1}^{M}\alpha _{m}G_{m}(x))
> 
> $$

- 训练误差分析

pass

- 算法解释

> 认为AdaBoost算法是模型为加法模型、损失函数为指数函数、学习算法为前向分步算法时的二类分类学习方法。
> 
> **前向分步算法**(forward stagewise algorithm)求解加法模型的想法是：从前往后，每步只学习一个基函数及其系数，逐步逼近优化目标函数式。
> 
> AdaBoost算法是前向分步加法算法的特例，此时基函数为基本分类器。
> 
> 前向分步算法中基函数及其系数的计算
> 
> pass

###### 提升树(boosting tree)

> 提升树是以决策树为基本分类器的提升方法，可用于分类或回归问题，是统计学习中性能最好的方法之一。

- 模型——基函数为决策树的加法模型

$$
f_{M}(x)=\sum_{m=1}^{M}T(x;\Theta _{m})
$$

- 策略

> 分类问题：指数损失函数
> 
> 回归问题：平方误差损失函数
> 
> 一般决策问题：一般损失函数

- 算法——前向分步算法
  
  > 平方误差损失函数时，拟合y与前一步获得的提升树的残差学习一个回归树；
  > 
  > 一般误差函数时，将损失函数负梯度在当前模型的值作为回归问题残差的近似值，用来拟合回归树，得到其叶结点区域。利用叶结点区域中使损失函数极小化的值来更新回归树。(梯度提升方法)

##### EM算法及其推广

> 期望极大算法(expectation maxmiization algorithm)是一种迭代算法，每次迭代时由两步组成：E步，求期望(expectation);M步，求最大化(maximization)。用于求极大后验概率估计，或对含有隐变量的概率模型的参数进行极大似然估计。

###### EM算法

> Y表示观测随机变量的数据，Z表示隐随机变量的数据。则Y和Z连在一起称为完全数据，Y又称为不完全数据。
> 
> θ为待估计的模型参数，则不完全数据Y的似然函数为P(Y|θ)，对数似然函数为L(θ)=logP(Y|θ)；Y和Z的联合概率分布的似然函数为P(Y,Z|θ)，对数似然函数为L(θ)=logP(Y,Z|θ)。**EM算法是求不完全数据L(θ)=logP(Y|θ)的极大似然估计。由于含有隐变量Z，故不能直接通过对似然函数求导来获得参数θ的值，[EM算法通过迭代逐步求解隐变量真实的期望值来得到确定的似然函数，从而得到参数θ的值](https://blog.csdn.net/xmu_jupiter/article/details/50936177)。**

- 算法

> 完全数据的对数似然函数L(θ)=logP(Y,Z|θ)关于在给定观测数据Y和当前参数θ下对未知观测数据Z的条件概率分布P(Z|Y,θ)的期望称为**Q函数**。实际上是求隐变量的期望
> 
> $$
> Q(\Theta ,\Theta ^{i})=E_{Z}\left [ logP(Y,Z|\Theta )|Y,\Theta ^{i} \right ]
> $$
> 
> 1. 设定参数θ的初始值，开始进行迭代
> 
> 2. E步：记θi为第i次迭代参数θ的估计值，在第i+1次迭代的E步，计算Q函数。
>    
>    $$
>    Q(\Theta ,\Theta ^{i})=E_{Z}\left [ logP(Y,Z|\Theta )|Y,\Theta ^{i} \right ] \newline
>                          =\sum_{z}logP(Y,Z|\Theta )P(Z|Y,\Theta ^{i})
>    $$
> 
> 3. M步：求使Q函数极大化的θ，确定第i+1次迭代的参数的估计值。
>    
>    $$
>    Q^{i+1}=\argmax\limits_{\Theta }Q(\Theta ,\Theta ^{i})
>    $$
> 
> 4. 重复第2步和第3步至收敛。满足如下收敛条件。
> 
> $$
> \left \| \Theta ^{i+1}-\Theta ^{i} \right \|< \epsilon _{1} \newline
> \left \| Q(\Theta ^{i+1},\Theta ^{i})-Q（\Theta ^{i}, \Theta ^{i}） \right \|< \epsilon _{2}
> $$

- EM算法的导出

pass

###### EM算法的收敛性

pass

###### EM算法在高斯混合模型中的应用

pass

###### EM算法的推广

pass

##### 隐马尔可夫模型

> 属于生成模型

###### 基本概念

- 隐马尔可夫模型

> 它是关于时序的概率模型，描述由隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测随机序列的过程。
> 
> **状态序列**(state sequence): 由隐藏的马尔科夫链随机生成的状态序列；
> 
> **观测序列**(observation sequence): 每个状态生成一个观测，由此产生的观测随机序列为观测序列；
> 
> 隐马尔科夫模型由初始状态概率向量π、状态转移概率矩阵A以及观测概率矩阵B确定，称为隐马尔科夫模型的三要素。其中π和A决定状态序列，B决定观测序列。
> 
> 该模型的两个基本假设：
> 
> 1. **齐次马尔可夫性假设**：隐藏的马尔可夫链在任意时刻t的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关，也与时刻无关。
>    
>    $$
>    P(i_{t}|i_{t-1}, o_{t-1}, \cdot \cdot \cdot ,i_{1},o_{1})=P(i_{t}|i_{t-1})
>    $$
> 
> 2. **观测独立性假设**：任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关。
>    
>    $$
>    P(o_{t}|i_{T},o_{T},i_{T-1},o_{T-1},\cdot \cdot \cdot , i_{t+1},o_{t+1},i_{t},i_{t-1},o_{t-1},\cdot \cdot \cdot ,i_{1},o_{1})=P(o_{t}|i_{t})
>    $$

- 观测序列的生成过程

> 输入：隐马尔可夫模型λ=(A,B,π)，观测序列长度T：
> 
> 输出：观测序列
> 
> 1. 按照初始状态分布π产生首个状态;
> 
> 2. 按照当前状态的观测概率分布生成其观测值；
> 
> 3. 按照当前状态的状态转移概率分布产生下个状态
> 
> 4. 更新时间t，若t<T，转第2步；否则，终止。

- **隐马尔可夫模型的3个基本问题**

> 1. **概率计算问题**：给定模型和观测序列，计算给定模型下，**观测序列出现的条件概率**
> 
> 2. **学习问题**：已知观测序列，估计模型λ=(A,B,π)参数，使得在该模型下，观测序列的概率最大。即用极大似然估计的方法估计参数。
> 
> 3. **预测问题**：给定观测序列，**求最有可能的对应的状态序列**。也称为解码(decoding)问题。

###### 概率计算算法

- 直接计算法

> 给定模型和观测序列，计算观测序列出现的概率。
> 
> 根据概率公式计算：列举所有长度为T的状态序列，计算状态序列与观测序列的联合概率，然后对所有可能的状态序列求和，得到观测序列的概率。
> 
> $$
> P(O|\lambda )=\sum_{I}P(O|I,\lambda )P(I|\lambda )\newline
>              =\sum_{i_{1},i_{2},\cdot \cdot \cdot ,i_{T}}\pi _{i_{i}}b_{i_{1}}(o_{1})a_{i_{1},i_{2}}b_{i_{2}}(o_{2})\cdot \cdot \cdot a_{i_{T-1},i_{T}}b_{i_{T}}(o_{T})
> $$
> 
> 该方法的计算量很大，是O(TN<sup>T</sup>)阶的(按照时间维度，每个时刻有N个状态，共T个时刻，第一个T是怎么来的？)。

- 前向算法

> 前向概率：给定隐马尔可夫模型λ，定义到时刻t部分观测序列为o<sub>1</sub>,o<sub>2</sub>,...,o<sub>t</sub>，,且状态为q<sub>i</sub>的概率为前向概率。
> 
> $$
> \alpha _{t}(i)=P(o_{1},o_{2},\cdot \cdot \cdot ,o_{t},i_{t}=q_{i}|\lambda )
> $$
> 
> 1. 初值
>    
>    $$
>    \alpha _{1}（i）=\pi _{i}b_{i}(o_{1}), i=1,2,\cdot \cdot \cdot ,N
>    $$
> 
> 2. 递推，对t=1,2,...,T-1,
>    
>    $$
>    \alpha _{t+1}(i)=\left [ \sum_{j=1}^{N}\alpha _{t}(j)a_{ji} \right ]b_{i}(o_{t+1}), i=1,2,...,N
>    $$
> 
> 3. 给定模型和观测序列时，观测序列的概率
>    
>    $$
>    P(O|\lambda )=\sum_{i=1}^{N}\alpha_{T}(i)
>    $$
> 
> 基于前向概率计算P(O|λ)的计算量为O(N<sup>2</sup>T)阶

- 后向算法

> 后向概率：给定隐马尔可夫模型λ，定义在时刻t状态为qi的条件下，从t+1到T的部分观测序列为o<sub>t+1</sub>, o<sub>t+2</sub>,...,o<sub> T</sub>的概率为后向概率。
> 
> $$
> \beta _{t}(u)=P(o_{t+1}, o_{t+2},\cdot \cdot \cdot ,o_{T}|i_{t}=q_{i},\lambda )
> $$
> 
> 1. 初始化后向概率，对最终时刻在状态为q<sub>i</sub>的条件下的概率为1
> 
> $$
> \beta _{T}(i)=1, i=1,2,\cdot \cdot \cdot ,N
> $$
> 
> 2. 递推，对t=T-1， T-2, ..., 1
> 
> $$
> \beta _{t}(i)=\sum_{j=1}^{N}a_{ij}b_{j}(o_{t+1})\beta _{t+1}(j),i=1,2,...,N
> $$
> 
> 3. 给定模型和观测序列时，观测序列的概率
> 
> $$
> P(O|\lambda )=\sum_{i=1}^{N}\pi _{i}b_{i}(o_{1})\beta _{1}(i)
> $$
> 
> 利用前向概率和后向概率的定义，可以将观测序列概率P(O|λ)  统一写成
> 
> $$
> P(O|\lambda )=\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha _{t}(i)a_{ij}b_{j}(o_{t+1})\beta _{t+1}(j),t=1,2,\cdot \cdot \cdot ,T-1
> $$

- 一些概率与期望值的计算

pass

###### 学习算法

> 训练数据包括观测序列和对应的状态序列时采用监督学习方法；
> 
> 训练数据仅包括观测序列时采用非监督学习方法——Baum-Welch算法(EM算法)

- 监督学习方法

> 1. 初始状态概率π<sub>i</sub>的估计为S个样本中初始状态为q<sub>i</sub>的频率；
> 
> 2. 转移概率a<sub>ij</sub>的估计。设样本中t时刻由状态i转移到t+1时刻状态j的频数为A<sub>ij</sub>，则状态转移概率a<sub>ij</sub>的估计为
>    
>    $$
>    \hat{a_{ij}}=\frac{A_{ij}}{\sum_{j=1}^{N}A_{ij}}， i=1,2，\cdot \cdot \cdot ，N;j=1,2,\cdot \cdot \cdot, N
>    $$
> 
> 3. 观测概率b<sub>j</sub>(k)的估计。状态为j且观测值为k的频数为B<sub>jk</sub>，则观测概率的估计为
>    
>    $$
>    \hat{b}_{j}(k)=\frac{B_{jk}}{\sum_{k=1}^{M}B_{jk}}, j=1,2,\cdot \cdot \cdot ,N;k=1,2,\cdot \cdot \cdot ,M
>    $$

- Baum-Welch算法
  
  > 1. 初始化参数。对n=0,选取a<sub>ij</sub><sup>(0)</sup>, b<sub>j</sub><sup>(0)</sup>, π<sub>i</sub><sup>(0)</sup>，得到模型λ<sup>(0)</sup>=(A<sup>(0)</sup>, B<sup>(0)</sup>, π<sup>(0)</sup>).
  > 
  > 2. 递推。对n=1,2,...,
  >    
  >    $$
  >    a_{ij}^{(n+1)}=\frac{\sum_{t=1}^{T-1} \xi _{t}(i,j)}{\sum_{t=1}^{T-1}\gamma _{t}(i)}\newline
  >    b_{j}(k)^{(n+1)}=\frac{\sum_{t=1,o_{t}=v_{k}}^{T}\gamma _{t}(j)}{\sum_{t=1}^{T}\gamma _{t}(j)}\newline
  >    \pi _{i}^{(n+1)}=\gamma _{1}(i)
  >    $$
  >    
  >    其中γ<sub>t</sub>(j)表示t时刻，状态为q<sub>j</sub>的概率
  >    
  >    $$
  >    \gamma _{t}(i)=\frac{\alpha _{t}(i)\beta _{t}(i)}{\sum_{j=1}^{N}\alpha _{t}(j)\beta _{t}(j)} \newline
  >    \xi _{t}(i,j)=\frac{\alpha _{t}(i)a_{ij}b_{j}(o_{t+1})\beta _{t+1}(j)}{\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha _{t}(i)a_{ij}b_{j}(o_{t+1})\beta _{t+1}(j)}
  >    $$
  > 
  > 3. 终止。得到模型参数λ<sup>(n+1)</sup>=(A<sup>(n+1)</sup>, B<sup>(n+1)</sup>, π<sup>(n+1)</sup>)

###### 预测算法

- 近似算法

> 选择每个时刻最有可能出现的状态i<sub>t</sub><sup>\*</sup>，从而得到一个状态序列I<sup>\*</sup>=(i<sub>1</sub><sup>\*</sup>, i<sub>2</sub><sup>\*</sup>, ..., i<sub>T</sub><sup>\*</sup>)作为预测结果。
> 
> $$
> \gamma _{t}(i)=\frac{\alpha _{t}(i)\beta _{t}(i)}{\sum_{j=1}^{N}\alpha _{t}(j)\beta _{t}(j)} \newline
> i_{t}^{*}=arg \max\limits_{1\leq i\leq N} \left [ \gamma _{t}(i) \right ],t=1,2,\cdot \cdot \cdot ,T
> $$
> 
> 该算法优点是计算简单；缺点是不能保证预测的状态序列整体是最优可能的状态序列。该算法得到的状态序列中可能存在转移概率为0的相邻状态.尽管如此，该算法仍然是有用的。

- 维特比算法

> 基于动态规划求解概率最大的路径(最优路径)。最优路径的子路径仍然是最优的。
> 
> 1. 初始化。其中δ<sub>t</sub>(i)表示t时刻状态为i的所有单个路径中的概率最大值，Ψ<sub>t</sub>(i)表示t时刻状态为i的所有单个路径中概率最大的路径的第t-1个结点。
>    
>    $$
>    \delta _{1}(i)=\pi _{i}b_{i}(o_{1}), i=1,2,\cdot \cdot \cdot ,N \newline
>    \Psi_{1}(i)=0, i=1,2,\cdot \cdot \cdot ,N
>    $$
> 
> 2. 递推，对t=2,3,...,T 
>    
>    $$
>    \delta _{t}(i)=\max \limits_{1\leq j\leq N}\left [ \delta _{t-1}(j)a_{ji} \right ]b_{i}(o_{t}), i=1,2,\cdot \cdot \cdot, N \newline
>    \Psi_{t}(i)=arg \max\limits_{1\leq j\leq N}\left [ \delta _{t-1}(j) a_{ji} \right ], i=1,2,\cdot \cdot \cdot ,N
>    $$
> 
> 3. 终止。
>    
>    $$
>    P^{*}=\max\limits_{1\leq i\leq N}\delta _{T}(i)\newline
>    i_{T}^{*}=arg \max\limits_{1\leq i\leq N}\left [ \delta _{T}(i) \right ]
>    $$
>    
>    4. 最优路径回溯。对t=T-1,T-2,...1，利用如下关系式得到最优路径I<sup>\*</sup>=(i<sub>1</sub><sup>\*</sup>, i<sub>2</sub><sup>\*</sup>, ..., i<sub>T</sub><sup>\*</sup>)
>    
>    $$
>    i_{t}^{*}=\Psi _{t+1}(i_{t+1}^{*})
>    $$

##### 条件随机场

> 条件随机场(conditional random field, CRF)是给定一组输入随机变量条件下输出另一组随机变量的条件概率分布模型。
> 
> 特点：假设输出随机变量构成马尔可夫随机场。
> 
> 线性链(linear chain)条件随机场为判别式模型，主要应用于标注问题。形式为对数线性模型，学习方法为极大似然估计或正则化的极大似然估计。

###### 概率无向图模型

- 模型定义

> **概率无向图模型(probabilistic unindirected graphical model)，又称为马尔可夫随机场(Markov random field)**，是可以用无向图表示的联合概率分布。该无向图表示的随机变量的联合概率分布满足成对马尔可夫性(pairwise Markov property)、局部马尔可夫性(local Markov property)和全局马尔可夫性(global Markov property)。它的最大特点是易于因子分解。
> 
> 无向图是指边没有方向的图。令结点和边的集合分别V和E，则图G=(V,E).
> 
> 概率图模型(probabilistic graphical model)是由图表示的概率分布。对于联合概率分布P(Y)，Y是一组随机变量。则在图G中，*结点表示一个随机变量Y，边表示随机变量之间的概率依赖关系*。
> 
> **成对马尔可夫性**。u和v是无向图G中任意两个不相邻的结点，它们所对应的随机变量分别为Y<sub>u</sub>和Y<sub>v</sub>，其他所有结点的集合为O，对应的随机变量组是Y<sub>O</sub>。成对马尔可夫性指给定随机组Y<sub>O</sub>的条件下随机变量Y<sub>u</sub>和Y<sub>v</sub>是条件独立的。
> 
> $$
> P(Y_{u},Y_{v}|Y_{O})=P(Y_{u}|Y_{O})P(Y_{v}|Y_{O})
> $$
> 
> **局部马尔可夫性**。v为无向图G中的任意一个结点，W是与v相邻的所有结点，O为v和W以外的其他所有结点，它们对应的随机变量(组)分别为Y<sub>v</sub>, Y<sub>W</sub>, Y<sub>b</sub>。全局马尔可夫性指给定随机变量组Y<sub>W</sub>的条件下随机变量Y<sub>v</sub>和随机变量组Y<sub>O</sub>是独立的。
> 
> $$
> P(Y_{v},Y_{O}|Y_{W})=P(Y_{v}|Y_{W})P(Y_{O}|Y_{W})
> $$
> 
> **全局马尔可夫性**。无向图中，结点集合A,B是被结点集合C分开的任意结点集合，它们所对应的随机变量组分别为Y<sub>A</sub>,Y<sub>B</sub>,Y<sub>C</sub>。全局马尔可夫性指给定随机变量组Y<sub>C</sub>条件下随机变量组Y<sub>A</sub>和Y<sub>B</sub>是条件独立的。
> 
> $$
> P(Y_{A},Y_{B}|Y_{C})=P(Y_{A}|Y_{C})P(Y_{B}|Y_{C})
> $$

- 概率无向图模型的因子分解

> **团**(clique)指无向图G中任何两个结点均有边连接的结点子集。
> 
> **最大团**(maximal clique)指无法加入无向图中的任何一个结点使团C成为更大的团。
> 
> **因子分解**(factorization)指将概率无向图模型的联合概率分布表示为其最大团上的随机变量的函数的乘积形式的操作。
> 
> **Hammersley-Cliffordd定理**：概率无向图模型的联合概率分布P(Y)表示如下。其中C为无向图的最大团，Y<sub>C</sub>是C的结点对应的随机变量组，Ψ<sub>C</sub>(Y<sub>C</sub>)是C上定义的严格正函数，乘积表示在无向图所有的最大团上进行。
> 
> $$
> P(Y)=\frac{1}{Z}\prod_{C}\Psi _{C}(Y_{C})\newline
> Z=\sum_{Y}\prod_{C}\Psi _{C}(Y_{C})
> $$
