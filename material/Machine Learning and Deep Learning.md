## 基础知识

### 数学相关概念

###### 全概率公式

设事件B1、B2、B3…Bn 构成一个完备事件组，即它们两两互不相容，其和为全集；并且P(Bi)大于0，则对任一事件A发生的概率有如下表示。

$$
P(A)=\sum_{i=1}^{n}P(B_{i})P(A|B_{i})
$$

###### 贝叶斯公式

随机事件A发生的情况下，是有原因Bi引起的概率表示如下。

$$
P(B_{i}|A)=\frac{P(B_{i})P(A|B_{i})}{P(A)}=\frac{P(B_{i})P(A|B_{i})}{\sum_{i=1}^{n}P(B_{i})P(A|B_{i})}
$$

###### 先验概率

根据以往经验和分析得到的概率，**用于执因求果**。如全概率公式中P(Bi)为先验概率，用于求事件A发生的概率。

###### 后验概率

某件事已经发生，想要计算这件事发生的原因是由某个因素引起的概率，**用于知果求因**。如贝叶斯公式中P(Bi|A)为后验概率，用于表示A发生是由Bi事件引起的概率。

###### [ 似然函数](https://zh.wikipedia.org/wiki/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0)

是一种关于[统计模型](https://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B "统计模型")中参数的函数，表示模型参数中的似然性。**似然性**则是用于在已知某些观测所得到的结果时，对有关事物之性质的参数进行估值。可理解为已知事件A发生的条件下，该事物性质的参数是b的可能性。

$$
L(b|A) = \alpha P(A|B=b)
$$

似然函数的重要性不是它的具体取值，而是当参数变化时函数到底变小还是变大

对同一个似然函数，其所代表的模型中，某项参数值具有多种可能，但如果存在一个参数值，使得它的函数值达到最大的话，那么这个值就是该项参数最为“合理”的参数值。 即**极大(最大)似然估计**，表示**知果求最可能的原因**

对数函数是严格单增的，所以极大*对数似然*的解与极大似然的解是相同的

###### [先验概率、后验概率、似然函数及贝叶斯公式的理解](https://www.zhihu.com/question/24261751/answer/158547500)

$$
P(B_{i}|A)=\frac{P(B_{i})P(A|B_{i})}{P(A)}=\frac{P(B_{i})P(A|B_{i})}{\sum_{i=1}^{n}P(B_{i})P(A|B_{i})}
$$

贝叶斯公式中P(Bi|A)表示后验概率，P(Bi)表示先验概率，P(A|Bi)表示似然函数中参数是Bi时A的概率，P(A)表示一种事实的概率。

###### [拉格朗日函数](https://zh.wikipedia.org/wiki/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0)

在数学的最优化问题中，拉格朗日乘数法是一种寻找多元函数在其变量受到一个或多个条件约束时的极值的方法。

###### 线性方程

指未知数都是一次的方程，包含两个未知数的一次方程为二元一次方程。其本质是等式两边乘以任何相同的非零数，方程式的解不变。

###### 对偶形式

pass

### 数据结构相关概念

##### [树](https://zh.wikipedia.org/wiki/%E6%A0%91_%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84)

![树的深度与高度图解](D:\Project\MyGithub\dl_Learning-materials\material\img\树的高度与深度.jpg)

                                                            图片来着[这里 ](https://stackoverflow.com/questions/2603692/what-is-the-difference-between-tree-depth-and-height)          

- **深度**：对于任意节点n,n的深度为从根到n的唯一路径长，**根的深度为0**；
- **高度**：对于任意节点n,n的高度为从n到一片树叶的最长路径长，**所有树叶的高度为0**；
- **节点的度**：一个节点含有的子树的个数称为该节点的度；
- **树的度**：一棵树中，最大的节点度称为树的度；
- **叶节点**或**终端节点**：度为零的节点；
- **非终端节点**或**分支节点**：度不为零的节点；
- **父亲节点**或**父节点**：若一个节点含有子节点，则这个节点称为其子节点的父节点；
- **孩子节点**或**子节点**：一个节点含有的子树的根节点称为该节点的子节点；
- **兄弟节点**：具有相同父节点的节点互称为兄弟节点；
- 节点的**层次**：从根开始定义起，根为第1层，根的子节点为第2层，以此类推；
- **堂兄弟节点**：父节点在同一层的节点互为堂兄弟；
- **节点的祖先**：从根到该节点所经分支上的所有节点；
- **子孙**：以某节点为根的子树中任一节点都称为该节点的子孙。
- **森林**：由m（m>=0）棵互不相交的树的集合称为森林；

### 机器学习相关概念

###### 数据集

> 训练集用于训练模型；
> 
> 验证集用于模型的选择；
> 
> 测试集用于最终对学习方法的评估；

###### 统计学习方法概论

统计学习方法是基于数据构建概率统计模型并运用模型对数据进行预测与分析的学科，由**监督学习**（supervised learning），**非监督学习**，**半监督学习和强化学习**（reinforcement learning）等组成。统计学习方法的三要素如下。

> 模型：所要学习的条件概率分布或决策函数；
> 
> 策略：学习或选择最优模型的准则，即损失函数(度量模型一次预测的好坏)和风险函数(度量平均意义下模型预测的好坏)的构建；
> 
> 算法：学习模型的具体计算方法，即求解最优化问题的算法

##### 模型选择

旨在避免过拟合并提高模型的预测能力。**模型选择常用的方法：正则化和交叉验证**。模型对未知数据的预测能力称为**泛化能力**。

> 过拟合 指学习时选择的模型包含的参数过多，以致于出现这一模型对已知数据预测的很好，但对未知数据预测很差的现象

###### 正则化

正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或罚项。正则化项一般是模型复杂度的单调递增函数，如正则化项可以是模型参数向量的范数。

###### 交叉验证

数据充足时，选择对验证集有最小预测误差的模型。否则采用交叉验证的方法，其基本思想是重复的使用数据，把数据分为训练集与测试集，在此基础上反复训练、测试以及模型选择。包括简单交叉验证，S折交叉验证和留一交叉验证。

> 简单交叉验证 将数据切分为训练集(70%)和测试集(30%)，然后用训练集在不同条件下(eg:不同参数个数)训练模型；然后在测试集上评测各模型的测试误差，选择误差最小的模型；
> 
> S折交叉验证 随机将数据切分为S个互不相交大小相同的子集，然后利用S-1个子集作为训练集，剩余的一个作为测试集训练模型。将上述过程对可能的S中集合重复进行，最后选择S次评测中测试误差最小的模型。该方法应用最多；
> 
> 留一交叉验证 S折交叉验证的特殊情况，即S等于样本容量。

###### 泛化能力

通常基于测试误差评价模型的泛化能力，但由于测试集的有限性，导致评测结果是不可靠的。因此使用泛化误差来反应模型的泛化能力。

### 评价指标

##### 分类问题

pass

### 距离度量函数

pass

## 机器学习方法
